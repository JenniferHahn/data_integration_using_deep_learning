{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "import gzip\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../src/data'\n",
    "mapping_corpus_path_2 = data_path + r'/product/lspc2020_to_tablecorpus/Cleaned'\n",
    "notebook_path = '../notebooks'\n",
    "product_path = os.path.join(data_path, 'product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = pd.read_json(os.path.join(mapping_corpus_path_2, 'df_large_matched.json'), compression='gzip', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_final_entities_df = pd.read_csv(os.path.join(notebook_path, 'electronics_clusters_15_tables.csv'), index_col=None)\n",
    "electronics_final_entities_list = electronics_final_entities_df['cluster_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "clothes_final_entities_df = pd.read_csv(os.path.join(notebook_path, 'clothes_clusters_10_tables.csv'), index_col=None)\n",
    "clothes_final_entities_list = clothes_final_entities_df['cluster_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_clusters_all_15_df = cluster_df[cluster_df['cluster_id'].isin(electronics_final_entities_list)]\n",
    "clothes_clusters_all_10_df = cluster_df[cluster_df['cluster_id'].isin(clothes_final_entities_list)]\n",
    "\n",
    "electronics_clusters_all_15_df.to_csv(os.path.join(mapping_corpus_path_2, 'electronics_clusters_all_15_tables.csv'), columns=None)\n",
    "clothes_clusters_all_10_df.to_csv(os.path.join(mapping_corpus_path_2, 'clothes_clusters_all_10_tables.csv'), columns=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-comedy",
   "metadata": {},
   "source": [
    "# Run from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(token_vector, stopwords_list):\n",
    "    return token_vector.apply(lambda token_list: [word for word in token_list if word not in stopwords_list])\n",
    "\n",
    "def remove_punctuation(token_vector):\n",
    "    return token_vector.apply(lambda token_list: [word for word in token_list if word not in string.punctuation])\n",
    "\n",
    "def jaccard_similarity_score(original, translation):\n",
    "    intersect = set(original).intersection(set(translation))\n",
    "    union = set(original).union(set(translation))\n",
    "    try:\n",
    "        return len(intersect) / len(union)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read final dataframes with all cluster_ids left for electronics and clothes\n",
    "electronics_clusters_all_15_df = pd.read_csv(os.path.join(mapping_corpus_path_2, 'electronics_clusters_all_15_tables.csv'), index_col=None)\n",
    "clothes_clusters_all_10_df = pd.read_csv(os.path.join(mapping_corpus_path_2, 'clothes_clusters_all_10_tables.csv'), index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate lists for final cluster_ids for electronics and clothes\n",
    "electronics_final_entities_df = pd.read_csv(os.path.join(notebook_path, 'electronics_clusters_15_tables.csv'),index_col=None)\n",
    "electronics_final_entities_list = electronics_final_entities_df['cluster_id']\n",
    "\n",
    "clothes_final_entities_df = pd.read_csv(os.path.join(notebook_path, 'clothes_clusters_10_tables.csv'),index_col=None)\n",
    "clothes_final_entities_list = clothes_final_entities_df['cluster_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate lists for valid electronics and clothes brands\n",
    "with open(os.path.join(product_path, 'brands_dict.json'), 'r', encoding='utf-8') as f:\n",
    "    brands_dict = json.load(f)\n",
    "\n",
    "electronics_valid_brands = brands_dict['electronics_total']\n",
    "clothes_valid_brands = brands_dict['clothes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase name column for similarity measure\n",
    "electronics_clusters_all_15_df['name'] = electronics_clusters_all_15_df['name'].apply(lambda row: str(row).lower())\n",
    "clothes_clusters_all_10_df['name'] = clothes_clusters_all_10_df['name'].apply(lambda row: str(row).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tokenizer for name column to get tokens for training the model, remove stopwords and punctuation\n",
    "electronics_clusters_all_15_df['tokens'] = electronics_clusters_all_15_df['name'].apply(lambda row: word_tokenize(row))\n",
    "electronics_clusters_all_15_df['tokens'] = remove_stopwords(electronics_clusters_all_15_df['tokens'], stopwords.words())\n",
    "electronics_clusters_all_15_df['tokens'] = remove_punctuation(electronics_clusters_all_15_df['tokens'])\n",
    "\n",
    "clothes_clusters_all_10_df['tokens'] = clothes_clusters_all_10_df['name'].apply(lambda row: word_tokenize(row))\n",
    "clothes_clusters_all_10_df['tokens'] = remove_stopwords(clothes_clusters_all_10_df['tokens'],stopwords.words())\n",
    "clothes_clusters_all_10_df['tokens'] = remove_punctuation(clothes_clusters_all_10_df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tagged words\n",
    "tagged_data_electronics = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(electronics_clusters_all_15_df['tokens'])]\n",
    "tagged_data_clothes = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(clothes_clusters_all_10_df['tokens'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model and vocabulary for electronics (do same for clothes later)\n",
    "model_electronics = Doc2Vec(vector_size=50, min_count=5, epochs=25, dm=0)\n",
    "model_electronics.build_vocab(tagged_data_electronics)\n",
    "# Train model\n",
    "model_electronics.train(tagged_data_electronics, total_examples=model_electronics.corpus_count, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-jurisdiction",
   "metadata": {},
   "source": [
    "### Change index label for testing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_single_cluster_id_df = electronics_clusters_all_15_df[electronics_clusters_all_15_df['cluster_id']==6443]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_brands = list(filter(lambda brand: brand in electronics_valid_brands, electronics_single_cluster_id_df['brand'].apply(lambda element: str(element).lower())))\n",
    "valid_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_brand = max(valid_brands, key=valid_brands.count)\n",
    "most_common_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_most_common = electronics_single_cluster_id_df[electronics_single_cluster_id_df['brand'].apply(lambda element: str(element).lower()) == most_common_brand].index[0]\n",
    "index_most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_doc = model_electronics.docvecs.most_similar(f'{index_most_common}', topn=electronics_clusters_all_15_df.shape[0])\n",
    "similar_doc_cluster = [tup for tup in similar_doc if int(tup[0]) in list(electronics_single_cluster_id_df.index)]\n",
    "similar_doc_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_doc_cluster_similarities = [tup[1] for tup in similar_doc_cluster]\n",
    "similar_doc_cluster_distances = [abs(x - similar_doc_cluster_similarities[i - 1]) for i, x in enumerate(similar_doc_cluster_similarities)][1:]\n",
    "max_distance = max(similar_doc_cluster_distances)\n",
    "max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance_index = similar_doc_cluster_distances.index(max_distance)\n",
    "max_distance_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_single_cluster_id_df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_score = electronics_single_cluster_id_df['name'].apply(lambda row: jaccard_similarity_score(row,electronics_single_cluster_id_df['name'].loc[int(index_most_common)]))\n",
    "jaccard_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
