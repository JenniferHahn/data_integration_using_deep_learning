{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import progressbar\n",
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from functions import jaccard_similarity_score, remove_stopwords ,remove_punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the paths and build table names for iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../src/data'\n",
    "mapping_corpus_path = data_path + r'/product/lspc2020_to_tablecorpus'\n",
    "mapping_corpus_path_2 = data_path + r'/product/lspc2020_to_tablecorpus/Cleaned'\n",
    "table_corpus_path = data_path + r'/product/product_top100/cleaned'\n",
    "table_corpus_path_with_id = data_path + r'/product/product_top100/cleaned/with_id'\n",
    "table_corpus_path2 = data_path + r'/product/product_minimum3/cleaned/with_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_files_mapping = [file for file in os.listdir(mapping_corpus_path_2) if file.endswith('.json.gz')]\n",
    "zip_files_tables = [file for file in os.listdir(table_corpus_path) if file.endswith('.json.gz')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match the number dictionaries with the information about the brand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electronics_cleaned = pd.read_json(mapping_corpus_path_2 + '/cleaned_electronics_all_brands', compression='gzip', orient='records', lines=True)\n",
    "df_clothes_cleaned = pd.read_json(mapping_corpus_path_2 + '/cleaned_clothes_all_brands', compression='gzip', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large = pd.read_json(os.path.join(mapping_corpus_path_2, 'df_large_matched'), compression='gzip', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_electronics = df_large.merge(df_electronics_cleaned, left_on=['table_id','row_id'], right_on = ['table_id','row_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_clothes = df_large.merge(df_clothes_cleaned, left_on=['table_id','row_id'], right_on = ['table_id','row_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_electronics.to_json(mapping_corpus_path_2 + '/joined_electronics_v2', compression='gzip', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_clothes.to_json(mapping_corpus_path_2 + '/joined_clothes_v2', compression='gzip', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_electronics = pd.read_json(os.path.join(mapping_corpus_path_2, 'joined_electronics_v2'), compression='gzip', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_clothes = pd.read_json(os.path.join(mapping_corpus_path_2, 'joined_clothes_v2'), compression='gzip', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get information about electronic clusters and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_electronics = df_joined_electronics.groupby('cluster_id').count()\n",
    "# only look at clusters that have at least one brand associated\n",
    "df_set_electronics = df_grouped_electronics[df_grouped_electronics['brand_y']>0].reset_index()[['cluster_id','table_id']].rename(columns={'table_id':'Amount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We discard all clusters with less than 2 entries, cause we cannot match anything there, so 1,6 million clusters remain\n",
    "df_set_electronics=df_set_electronics[df_set_electronics['Amount']>1]\n",
    "df_15_electronics=df_set_electronics[df_set_electronics['Amount']>15]\n",
    "df_15_electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge brand name to cluster amount\n",
    "df_cluster_brand = df_15_electronics[df_15_electronics['Amount']<200].merge(df_joined_electronics.dropna()[['cluster_id','brand_y']].drop_duplicates('cluster_id', keep='last'), left_on=['cluster_id'], right_on = ['cluster_id'], how='left')\n",
    "df_cluster_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean product column and lowercase\n",
    "df_joined_electronics=df_joined_electronics.dropna(subset = ['name'])\n",
    "df_joined_electronics['name'] = df_joined_electronics['name'].apply(lambda row: row.lower())\n",
    "df_joined_electronics\n",
    "#get only cluster ids with at least one brand electronics\n",
    "df_compare_electronics = df_joined_electronics[df_joined_electronics['cluster_id'].isin(df_set_electronics['cluster_id'].tolist())]\n",
    "#merge with set to get amount of tables per cluster in overview\n",
    "df_compare_electronics = df_compare_electronics.merge(df_set_electronics, left_on=['cluster_id'], right_on = ['cluster_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(token_vector):\n",
    "    return token_vector.apply(lambda token_list: [word for word in token_list if word not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use tokenizer for product names to get tokes for training the model\n",
    "df_compare_electronics['product_tokes'] = df_compare_electronics['name'].apply(lambda row: word_tokenize(row))\n",
    "df_compare_electronics['product_tokes'] = remove_stopwords(df_compare_electronics['product_tokes'],stopwords.words())\n",
    "df_compare_electronics['product_tokes'] = remove_punctuation (df_compare_electronics['product_tokes'])\n",
    "#get tagged words\n",
    "tagged_data = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(df_compare_electronics['product_tokes'])]\n",
    "# build model and vocabulary\n",
    "model = Doc2Vec(vector_size=50, min_count = 5, epochs = 25, dm = 0)\n",
    "model.build_vocab(tagged_data)\n",
    "# Train model\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity_score(original, translation):\n",
    "    intersect = set(original).intersection(set(translation))\n",
    "    union = set(original).union(set(translation))\n",
    "    try:\n",
    "        return len(intersect) / len(union)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cluster ids for basline products and with that indices of top products to use model\n",
    "#1524820,47566,6076,14418,28307,33570,39040,51314,99153,215254,685416, 984421 , 1808651,2887810,34506065,47841827,620473,56116,94055, 150211,182246, 516888, 562955 \n",
    "top_clusters_list = df_15_electronics['cluster_id'].tolist()\n",
    "index_top_clusters_list=[]\n",
    "for id in top_clusters_list:\n",
    "    index_top_clusters_list.append(df_compare_electronics[df_compare_electronics['cluster_id']==id].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most similar products for each of the base clusters and save them if they have more than 5 tables\n",
    "electronics_clusters_search=[]\n",
    "for i in index_top_clusters_list:\n",
    "    similar_doc = model.docvecs.most_similar(f'{i}', topn = 20)\n",
    "    electronics_clusters_search.append(int(i))\n",
    "    for index, similarity in similar_doc:\n",
    "        if df_compare_electronics.iloc[int(index)]['Amount']>12:\n",
    "            electronics_clusters_search.append(int(index))\n",
    "    jaccard_score = df_compare_electronics['product_tokes'].apply(lambda row: jaccard_similarity_score(row,df_compare_electronics.iloc[int(i)]['product_tokes']) )\n",
    "    indizes=sorted(range(len(jaccard_score)), key=lambda i: jaccard_score[i])[-20:]\n",
    "    for index in indizes:\n",
    "         if df_compare_electronics.iloc[int(index)]['Amount']>12:\n",
    "            electronics_clusters_search.append(int(index))    \n",
    "df_electroncis_final = df_compare_electronics.iloc[electronics_clusters_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electroncis_final.drop_duplicates('cluster_id', keep='first').to_excel(\"Final_Electronics_v3.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster statistics for product category clothes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_clothes = df_joined_clothes.groupby('cluster_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only look at clusters that have at least one brand associated\n",
    "df_set_clothes = df_grouped_clothes[df_grouped_clothes['brand_y']>0].reset_index()[['cluster_id','table_id']].rename(columns={'table_id':'Amount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We discard all clusters with less than 2 entries, cause we cannot match anything there, so 1,6 million clusters remain\n",
    "df_set_clothes=df_set_clothes[df_set_clothes['Amount']>1]\n",
    "df_set_clothes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10_clothes=df_set_clothes[df_set_clothes['Amount']>10]\n",
    "df_10_clothes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge brand name to cluster amount\n",
    "df_cluster_brand_clothes = df_10_clothes[df_10_clothes['Amount']<400].merge(df_joined_clothes.dropna()[['cluster_id','brand_y']].drop_duplicates('cluster_id', keep='last'), left_on=['cluster_id'], right_on = ['cluster_id'], how='left')\n",
    "df_cluster_brand_clothes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_clothes=df_joined_clothes.dropna(subset = ['name'])\n",
    "#clean product column and lowercase\n",
    "df_joined_clothes['name'] = df_joined_clothes['name'].apply(lambda row: row.lower())\n",
    "df_joined_clothes\n",
    "#get only cluster ids with at least one brand electronics\n",
    "df_compare_clothes = df_joined_clothes[df_joined_clothes['cluster_id'].isin(df_set_clothes['cluster_id'].tolist())]\n",
    "#merge with set to get amount of tables per cluster in overview\n",
    "df_compare_clothes = df_compare_clothes.merge(df_set_clothes, left_on=['cluster_id'], right_on = ['cluster_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use tokenizer for product names to get tokes for training the model\n",
    "df_compare_clothes['product_tokes'] = df_compare_clothes['name'].apply(lambda row: word_tokenize(row))\n",
    "df_compare_clothes['product_tokes'] = remove_stopwords(df_compare_clothes['product_tokes'],stopwords.words())\n",
    "df_compare_clothes['product_tokes'] = remove_punctuation (df_compare_clothes['product_tokes'])\n",
    "#get tagged words\n",
    "tagged_data = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(df_compare_clothes['product_tokes'])]\n",
    "# build model and vocabulary\n",
    "model = Doc2Vec(vector_size=50, min_count = 5, epochs = 25, dm = 0)\n",
    "model.build_vocab(tagged_data)\n",
    "# Train model\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cluster ids and with that indices of top products to use model\n",
    "#5310, 58043,104343,142594,174327, 186753,421372,677207,834201, 881202,  895708,939889, 1249086,1290229, 1852022,2459966, 2732926 , 22374915, 22374918, 26097914,44159446, 58592784, 78110534,135583,148199, 200956, 950691, 1592417,2464591\n",
    "top_clusters_list = df_10_clothes['cluster_id'].tolist()\n",
    "index_top_clusters_list=[]\n",
    "for id in top_clusters_list:\n",
    "    index_top_clusters_list.append(df_compare_clothes[df_compare_clothes['cluster_id']==id].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most similar products for each of the base clusters and save them if they have more than 5 tables\n",
    "clothes_clusters_search=[]\n",
    "for i in index_top_clusters_list:\n",
    "    similar_doc = model.docvecs.most_similar(f'{i}', topn = 15)\n",
    "    clothes_clusters_search.append(int(i))\n",
    "    for index, similarity in similar_doc:\n",
    "        if df_compare_clothes.iloc[int(index)]['Amount']>8:\n",
    "            clothes_clusters_search.append(int(index))\n",
    "    jaccard_score = df_compare_clothes['product_tokes'].apply(lambda row: jaccard_similarity_score(row,df_compare_clothes.iloc[int(i)]['product_tokes']) )\n",
    "    indizes=sorted(range(len(jaccard_score)), key=lambda i: jaccard_score[i])[-20:]\n",
    "    for index in indizes:\n",
    "         if df_compare_clothes.iloc[int(index)]['Amount']>8:\n",
    "            clothes_clusters_search.append(int(index))    \n",
    "df_clothes_final = df_compare_clothes.iloc[clothes_clusters_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clothes_final.drop_duplicates('cluster_id', keep='first').to_excel(\"Final_Clothes_v3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}