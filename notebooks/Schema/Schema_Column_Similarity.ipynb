{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "240dce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re  \n",
    "import pandas as pd\n",
    "import json\n",
    "from time import time\n",
    "from collections import defaultdict  \n",
    "\n",
    "import spacy\n",
    "\n",
    "import logging \n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65ec9ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.1.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.1 MB 8.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[K     |████████████████████████████████| 130 kB 48.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: setuptools in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from spacy) (2.25.1)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 47.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp38-cp38-manylinux2014_x86_64.whl (13.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.7 MB 46.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from spacy) (2.11.3)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 45.4 MB/s eta 0:00:01     |████▊                           | 1.5 MB 45.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from spacy) (4.59.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from spacy) (1.20.1)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
      "\u001b[K     |████████████████████████████████| 454 kB 46.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/bizer-tp2021/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, pydantic, preshed, blis, thinc, spacy-legacy, pathy, spacy\n",
      "Successfully installed blis-0.7.5 catalogue-2.0.6 cymem-2.0.6 murmurhash-1.0.6 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 spacy-3.1.4 spacy-legacy-3.0.8 srsly-2.4.2 thinc-8.0.13 typer-0.4.0 wasabi-0.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d60070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.1\n",
      "  latest version: 4.10.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/bizer-tp2021/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - gensim\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.10.3               |   py38h578d9bd_3         3.1 MB  conda-forge\n",
      "    gensim-4.0.1               |   py38h2531618_0        18.2 MB\n",
      "    python_abi-3.8             |           2_cp38           4 KB  conda-forge\n",
      "    smart_open-5.2.1           |     pyhd8ed1ab_0          43 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        21.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  gensim             pkgs/main/linux-64::gensim-4.0.1-py38h2531618_0\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.8-2_cp38\n",
      "  smart_open         conda-forge/noarch::smart_open-5.2.1-pyhd8ed1ab_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda              pkgs/main::conda-4.10.1-py38h06a4308_1 --> conda-forge::conda-4.10.3-py38h578d9bd_3\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "gensim-4.0.1         | 18.2 MB   | ##################################### | 100% \n",
      "smart_open-5.2.1     | 43 KB     | ##################################### | 100% \n",
      "python_abi-3.8       | 4 KB      | ##################################### | 100% \n",
      "conda-4.10.3         | 3.1 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3f053315",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/work-ceph/bizer-tp2021/data_integration_using_deep_learning/src/data/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bd6aa01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c2ab5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookPath = path + 'Book/All/'\n",
    "\n",
    "bookFilenames = next(walk(bookPath), (None, None, []))[2]\n",
    "\n",
    "bookData = []\n",
    "\n",
    "for book in bookFilenames[:5]:\n",
    "    with gzip.open(bookPath + book, 'r') as dataFile:\n",
    "        for line in dataFile:\n",
    "            lineData = json.loads(line.decode('utf-8'))\n",
    "            bookData.append(lineData)\n",
    "bookDF = pd.DataFrame(bookData)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9b1543e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>offers</th>\n",
       "      <th>bookedition</th>\n",
       "      <th>page_url</th>\n",
       "      <th>isbn</th>\n",
       "      <th>datepublished</th>\n",
       "      <th>genre</th>\n",
       "      <th>url</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A Collection of 11 Photographs Taken in Nazi B...</td>\n",
       "      <td>11 vintage, black and white photographs ( Size...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'availability': 'InStock', 'price': '12000.00...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.foldvaribooks.com/searchResults.ph...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Photo Album of Agricultural Exhibition and Fa...</td>\n",
       "      <td>The album was a present for Imre Dögei (1912–1...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'availability': 'InStock', 'price': '750.00',...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.foldvaribooks.com/searchResults.ph...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Illés koncert. Budapest - Sportcsarnok. 1981. ...</td>\n",
       "      <td>Illustrated concert program of the first reuni...</td>\n",
       "      <td>[Illés, Lajos]; [Szörényi, Levente]; [Bródy, J...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'price': '600.00', 'availability': 'InStock',...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.foldvaribooks.com/advSearchResults...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A Gépember. [The Man Machine.]</td>\n",
       "      <td>Extremely scarce original photograph of the ro...</td>\n",
       "      <td>[Bortnyik, Sándor]; [Zelenka, László]; Korsche...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'availability': 'InStock', 'price': '800.00',...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.foldvaribooks.com/advSearchResults...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Photoalbum] Emlékeim a Tanácsköztársaság idej...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'price': '1500.00', 'availability': 'InStock'...</td>\n",
       "      <td>Amateur photoalbum. More than hundred black an...</td>\n",
       "      <td>https://www.foldvaribooks.com/pages/books/681/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                                               name  \\\n",
       "0       0  A Collection of 11 Photographs Taken in Nazi B...   \n",
       "1       1  [Photo Album of Agricultural Exhibition and Fa...   \n",
       "2       2  Illés koncert. Budapest - Sportcsarnok. 1981. ...   \n",
       "3       3                     A Gépember. [The Man Machine.]   \n",
       "4       4  [Photoalbum] Emlékeim a Tanácsköztársaság idej...   \n",
       "\n",
       "                                         description  \\\n",
       "0  11 vintage, black and white photographs ( Size...   \n",
       "1  The album was a present for Imre Dögei (1912–1...   \n",
       "2  Illustrated concert program of the first reuni...   \n",
       "3  Extremely scarce original photograph of the ro...   \n",
       "4                                               None   \n",
       "\n",
       "                                              author publisher  \\\n",
       "0                                               None      None   \n",
       "1                                               None      None   \n",
       "2  [Illés, Lajos]; [Szörényi, Levente]; [Bródy, J...      None   \n",
       "3  [Bortnyik, Sándor]; [Zelenka, László]; Korsche...      None   \n",
       "4                                               None      None   \n",
       "\n",
       "                                              offers  \\\n",
       "0  {'availability': 'InStock', 'price': '12000.00...   \n",
       "1  {'availability': 'InStock', 'price': '750.00',...   \n",
       "2  {'price': '600.00', 'availability': 'InStock',...   \n",
       "3  {'availability': 'InStock', 'price': '800.00',...   \n",
       "4  {'price': '1500.00', 'availability': 'InStock'...   \n",
       "\n",
       "                                         bookedition  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4  Amateur photoalbum. More than hundred black an...   \n",
       "\n",
       "                                            page_url isbn datepublished genre  \\\n",
       "0  https://www.foldvaribooks.com/searchResults.ph...  NaN           NaN   NaN   \n",
       "1  https://www.foldvaribooks.com/searchResults.ph...  NaN           NaN   NaN   \n",
       "2  https://www.foldvaribooks.com/advSearchResults...  NaN           NaN   NaN   \n",
       "3  https://www.foldvaribooks.com/advSearchResults...  NaN           NaN   NaN   \n",
       "4  https://www.foldvaribooks.com/pages/books/681/...  NaN           NaN   NaN   \n",
       "\n",
       "   url price  \n",
       "0  NaN   NaN  \n",
       "1  NaN   NaN  \n",
       "2  NaN   NaN  \n",
       "3  NaN   NaN  \n",
       "4  NaN   NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d38fbdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1061.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>143.592837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>102.881587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>397.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id\n",
       "count  1061.000000\n",
       "mean    143.592837\n",
       "std     102.881587\n",
       "min       0.000000\n",
       "25%      53.000000\n",
       "50%     129.000000\n",
       "75%     218.000000\n",
       "max     397.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcec4bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id             0\n",
       "name               1\n",
       "description      328\n",
       "author            42\n",
       "publisher        455\n",
       "offers           539\n",
       "bookedition      836\n",
       "page_url           0\n",
       "isbn             522\n",
       "datepublished    663\n",
       "genre            664\n",
       "url              663\n",
       "price            663\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookDF.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4b4c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_empty_rows(df):\n",
    "    rows = []\n",
    "    for i, row in enumerate(df['name']):\n",
    "        if type(row) != str:\n",
    "            rows.append(i)\n",
    "    df_clean = df.drop(index=rows)\n",
    "    df_clean = df_clean.reset_index(drop=True)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1df01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = delete_empty_rows(bookDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d59eb377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>143.623585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>102.925272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>129.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>397.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id\n",
       "count  1060.000000\n",
       "mean    143.623585\n",
       "std     102.925272\n",
       "min       0.000000\n",
       "25%      53.000000\n",
       "50%     129.500000\n",
       "75%     218.000000\n",
       "max     397.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da76cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_empty_rows(df):\n",
    "    rows = []\n",
    "    for i, row in enumerate(df['author']):\n",
    "        if type(row) != str:\n",
    "            rows.append(i)\n",
    "    df_clean = df.drop(index=rows)\n",
    "    df_clean = df_clean.reset_index(drop=True)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cae670c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = delete_empty_rows(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a853734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_empty_rows(df):\n",
    "    rows = []\n",
    "    for i, row in enumerate(df['publisher']):\n",
    "        if type(row) != str:\n",
    "            rows.append(i)\n",
    "    df_clean = df.drop(index=rows)\n",
    "    df_clean = df_clean.reset_index(drop=True)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ab8c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = delete_empty_rows(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3df0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_empty_rows(df):\n",
    "    rows = []\n",
    "    for i, row in enumerate(df['datepublished']):\n",
    "        if type(row) != str:\n",
    "            rows.append(i)\n",
    "    df_clean = df.drop(index=rows)\n",
    "    df_clean = df_clean.reset_index(drop=True)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed626200",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = delete_empty_rows(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4bbf867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id             0\n",
       "name               0\n",
       "description        0\n",
       "author             0\n",
       "publisher          0\n",
       "offers           361\n",
       "bookedition      361\n",
       "page_url           0\n",
       "isbn               0\n",
       "datepublished      0\n",
       "genre              1\n",
       "url                0\n",
       "price              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3328bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(df, keep_numbers='yes'): # keep numbers as default\n",
    "    if keep_numbers=='yes':\n",
    "        df[\"new_column\"] = df['name'].str.replace('[^\\w\\s]', ' ')\n",
    "    else:\n",
    "        df[\"new_column\"] = df['name'].str.replace('[^A-Za-z_\\s]', ' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "991c6521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-f758b1c2d86d>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"new_column\"] = df['name'].str.replace('[^\\w\\s]', ' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>offers</th>\n",
       "      <th>bookedition</th>\n",
       "      <th>page_url</th>\n",
       "      <th>isbn</th>\n",
       "      <th>datepublished</th>\n",
       "      <th>genre</th>\n",
       "      <th>url</th>\n",
       "      <th>price</th>\n",
       "      <th>new_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Healing</td>\n",
       "      <td>FINALIST FOR THE NATIONAL BOOK AWARD ‘A litera...</td>\n",
       "      <td>Gayl Jones</td>\n",
       "      <td>Virago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.virago.co.uk/titles/gayl-jones/the...</td>\n",
       "      <td>9780349012186</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>[Modern &amp; Contemporary Fiction (post C 1945), ...</td>\n",
       "      <td>https://www.virago.co.uk/titles/gayl-jones/the...</td>\n",
       "      <td>Price: £9.99</td>\n",
       "      <td>The Healing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Foreign Brides</td>\n",
       "      <td>Funny, irreverent, dark, and tender – a startl...</td>\n",
       "      <td>Elena Lappin</td>\n",
       "      <td>Virago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.virago.co.uk/titles/elena-lappin/f...</td>\n",
       "      <td>9780349008868</td>\n",
       "      <td>2016-07-21</td>\n",
       "      <td>[Fiction &amp; Related Items, Fiction: Special Fea...</td>\n",
       "      <td>https://www.virago.co.uk/titles/elena-lappin/f...</td>\n",
       "      <td>Price: £9.99</td>\n",
       "      <td>Foreign Brides</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Enchanted April</td>\n",
       "      <td>‘An enchanting novel, witty, touching and very...</td>\n",
       "      <td>Elizabeth von Arnim</td>\n",
       "      <td>Virago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.virago.co.uk/titles/elizabeth-von-...</td>\n",
       "      <td>9780748121533</td>\n",
       "      <td>2010-08-05</td>\n",
       "      <td>[Classic Fiction (pre C 1945), Fiction &amp; Relat...</td>\n",
       "      <td>https://www.virago.co.uk/titles/elizabeth-von-...</td>\n",
       "      <td>Price: £8.99</td>\n",
       "      <td>The Enchanted April</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Apple Bough</td>\n",
       "      <td>So your brother’s a world-famous violinist? Th...</td>\n",
       "      <td>Noel Streatfeild</td>\n",
       "      <td>Virago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.virago.co.uk/titles/noel-streatfei...</td>\n",
       "      <td>9780349010915</td>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>[Modern &amp; Contemporary Fiction (post C 1945), ...</td>\n",
       "      <td>https://www.virago.co.uk/titles/noel-streatfei...</td>\n",
       "      <td>Price: £6.99</td>\n",
       "      <td>Apple Bough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Thursday's Children</td>\n",
       "      <td>Doone Penny is a child with a gift – he was bo...</td>\n",
       "      <td>Rumer Godden</td>\n",
       "      <td>Virago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.virago.co.uk/titles/rumer-godden/t...</td>\n",
       "      <td>9781844088485</td>\n",
       "      <td>2013-04-04</td>\n",
       "      <td>[General Fiction (children's, Children's, Teen...</td>\n",
       "      <td>https://www.virago.co.uk/titles/rumer-godden/t...</td>\n",
       "      <td>Price: £7.99</td>\n",
       "      <td>Thursday s Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>393</td>\n",
       "      <td>The Magic Toyshop</td>\n",
       "      <td>Cover design by Jacqueline Groag ‘This crazy w...</td>\n",
       "      <td>Angela Carter</td>\n",
       "      <td>Virago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.virago.co.uk/titles/angela-carter/...</td>\n",
       "      <td>9781844085231</td>\n",
       "      <td>2008-07-03</td>\n",
       "      <td>[Modern &amp; Contemporary Fiction (post C 1945), ...</td>\n",
       "      <td>https://www.virago.co.uk/titles/angela-carter/...</td>\n",
       "      <td>Price: £12.99</td>\n",
       "      <td>The Magic Toyshop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>394</td>\n",
       "      <td>In A Summer Season</td>\n",
       "      <td>In a Summer Season is one of Elizabeth Taylor’...</td>\n",
       "      <td>Elizabeth Taylor</td>\n",
       "      <td>Virago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.virago.co.uk/titles/elizabeth-tayl...</td>\n",
       "      <td>9780748131013</td>\n",
       "      <td>2011-07-07</td>\n",
       "      <td>[Classic Fiction (pre C 1945), Fiction &amp; Relat...</td>\n",
       "      <td>https://www.virago.co.uk/titles/elizabeth-tayl...</td>\n",
       "      <td>Price: £8.99</td>\n",
       "      <td>In A Summer Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>395</td>\n",
       "      <td>Chasm: A Weekend</td>\n",
       "      <td>‘Tanning’s fictional debut unquestionably dese...</td>\n",
       "      <td>Dorothea Tanning</td>\n",
       "      <td>Virago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.virago.co.uk/titles/dorothea-tanni...</td>\n",
       "      <td>9780349012629</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>[Modern &amp; Contemporary Fiction (post C 1945), ...</td>\n",
       "      <td>https://www.virago.co.uk/titles/dorothea-tanni...</td>\n",
       "      <td>Price: £8.99</td>\n",
       "      <td>Chasm  A Weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>396</td>\n",
       "      <td>Don't Look Now And Other Stories</td>\n",
       "      <td>John and Laura have come to Venice to try and ...</td>\n",
       "      <td>Daphne Du Maurier</td>\n",
       "      <td>Virago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.virago.co.uk/titles/daphne-du-maur...</td>\n",
       "      <td>9780349006611</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>[Fiction &amp; Related Items, Fiction: Special Fea...</td>\n",
       "      <td>https://www.virago.co.uk/titles/daphne-du-maur...</td>\n",
       "      <td>Price: £14.99</td>\n",
       "      <td>Don t Look Now And Other Stories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>397</td>\n",
       "      <td>The World My Wilderness</td>\n",
       "      <td>It is 1946 and the people of France and Englan...</td>\n",
       "      <td>Rose Macaulay</td>\n",
       "      <td>Virago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.virago.co.uk/titles/rose-macaulay/...</td>\n",
       "      <td>9780349010014</td>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>[Classic Fiction (pre C 1945), Fiction &amp; Relat...</td>\n",
       "      <td>https://www.virago.co.uk/titles/rose-macaulay/...</td>\n",
       "      <td>Price: £8.99</td>\n",
       "      <td>The World My Wilderness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id                              name  \\\n",
       "0         0                       The Healing   \n",
       "1         1                    Foreign Brides   \n",
       "2         2               The Enchanted April   \n",
       "3         3                       Apple Bough   \n",
       "4         4               Thursday's Children   \n",
       "..      ...                               ...   \n",
       "356     393                 The Magic Toyshop   \n",
       "357     394                In A Summer Season   \n",
       "358     395                  Chasm: A Weekend   \n",
       "359     396  Don't Look Now And Other Stories   \n",
       "360     397           The World My Wilderness   \n",
       "\n",
       "                                           description               author  \\\n",
       "0    FINALIST FOR THE NATIONAL BOOK AWARD ‘A litera...           Gayl Jones   \n",
       "1    Funny, irreverent, dark, and tender – a startl...         Elena Lappin   \n",
       "2    ‘An enchanting novel, witty, touching and very...  Elizabeth von Arnim   \n",
       "3    So your brother’s a world-famous violinist? Th...     Noel Streatfeild   \n",
       "4    Doone Penny is a child with a gift – he was bo...         Rumer Godden   \n",
       "..                                                 ...                  ...   \n",
       "356  Cover design by Jacqueline Groag ‘This crazy w...        Angela Carter   \n",
       "357  In a Summer Season is one of Elizabeth Taylor’...     Elizabeth Taylor   \n",
       "358  ‘Tanning’s fictional debut unquestionably dese...     Dorothea Tanning   \n",
       "359  John and Laura have come to Venice to try and ...    Daphne Du Maurier   \n",
       "360  It is 1946 and the people of France and Englan...        Rose Macaulay   \n",
       "\n",
       "    publisher offers bookedition  \\\n",
       "0      Virago    NaN         NaN   \n",
       "1      Virago    NaN         NaN   \n",
       "2      Virago    NaN         NaN   \n",
       "3      Virago    NaN         NaN   \n",
       "4      Virago    NaN         NaN   \n",
       "..        ...    ...         ...   \n",
       "356    Virago    NaN         NaN   \n",
       "357    Virago    NaN         NaN   \n",
       "358    Virago    NaN         NaN   \n",
       "359    Virago    NaN         NaN   \n",
       "360    Virago    NaN         NaN   \n",
       "\n",
       "                                              page_url           isbn  \\\n",
       "0    https://www.virago.co.uk/titles/gayl-jones/the...  9780349012186   \n",
       "1    https://www.virago.co.uk/titles/elena-lappin/f...  9780349008868   \n",
       "2    https://www.virago.co.uk/titles/elizabeth-von-...  9780748121533   \n",
       "3    https://www.virago.co.uk/titles/noel-streatfei...  9780349010915   \n",
       "4    https://www.virago.co.uk/titles/rumer-godden/t...  9781844088485   \n",
       "..                                                 ...            ...   \n",
       "356  https://www.virago.co.uk/titles/angela-carter/...  9781844085231   \n",
       "357  https://www.virago.co.uk/titles/elizabeth-tayl...  9780748131013   \n",
       "358  https://www.virago.co.uk/titles/dorothea-tanni...  9780349012629   \n",
       "359  https://www.virago.co.uk/titles/daphne-du-maur...  9780349006611   \n",
       "360  https://www.virago.co.uk/titles/rose-macaulay/...  9780349010014   \n",
       "\n",
       "    datepublished                                              genre  \\\n",
       "0      2019-10-03  [Modern & Contemporary Fiction (post C 1945), ...   \n",
       "1      2016-07-21  [Fiction & Related Items, Fiction: Special Fea...   \n",
       "2      2010-08-05  [Classic Fiction (pre C 1945), Fiction & Relat...   \n",
       "3      2018-07-05  [Modern & Contemporary Fiction (post C 1945), ...   \n",
       "4      2013-04-04  [General Fiction (children's, Children's, Teen...   \n",
       "..            ...                                                ...   \n",
       "356    2008-07-03  [Modern & Contemporary Fiction (post C 1945), ...   \n",
       "357    2011-07-07  [Classic Fiction (pre C 1945), Fiction & Relat...   \n",
       "358    2019-01-31  [Modern & Contemporary Fiction (post C 1945), ...   \n",
       "359    2015-10-01  [Fiction & Related Items, Fiction: Special Fea...   \n",
       "360    2018-02-08  [Classic Fiction (pre C 1945), Fiction & Relat...   \n",
       "\n",
       "                                                   url          price  \\\n",
       "0    https://www.virago.co.uk/titles/gayl-jones/the...   Price: £9.99   \n",
       "1    https://www.virago.co.uk/titles/elena-lappin/f...   Price: £9.99   \n",
       "2    https://www.virago.co.uk/titles/elizabeth-von-...   Price: £8.99   \n",
       "3    https://www.virago.co.uk/titles/noel-streatfei...   Price: £6.99   \n",
       "4    https://www.virago.co.uk/titles/rumer-godden/t...   Price: £7.99   \n",
       "..                                                 ...            ...   \n",
       "356  https://www.virago.co.uk/titles/angela-carter/...  Price: £12.99   \n",
       "357  https://www.virago.co.uk/titles/elizabeth-tayl...   Price: £8.99   \n",
       "358  https://www.virago.co.uk/titles/dorothea-tanni...   Price: £8.99   \n",
       "359  https://www.virago.co.uk/titles/daphne-du-maur...  Price: £14.99   \n",
       "360  https://www.virago.co.uk/titles/rose-macaulay/...   Price: £8.99   \n",
       "\n",
       "                           new_column  \n",
       "0                         The Healing  \n",
       "1                      Foreign Brides  \n",
       "2                 The Enchanted April  \n",
       "3                         Apple Bough  \n",
       "4                 Thursday s Children  \n",
       "..                                ...  \n",
       "356                 The Magic Toyshop  \n",
       "357                In A Summer Season  \n",
       "358                  Chasm  A Weekend  \n",
       "359  Don t Look Now And Other Stories  \n",
       "360           The World My Wilderness  \n",
       "\n",
       "[361 rows x 14 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punctuations(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15161f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_final  = df_clean['new_column'].values\n",
    "book_final[80000:80200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b38b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(book_final)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afc171e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['the', 'healing'], tags=['0']),\n",
       " TaggedDocument(words=['foreign', 'brides'], tags=['1']),\n",
       " TaggedDocument(words=['the', 'enchanted', 'april'], tags=['2']),\n",
       " TaggedDocument(words=['apple', 'bough'], tags=['3']),\n",
       " TaggedDocument(words=['thursday', 's', 'children'], tags=['4']),\n",
       " TaggedDocument(words=['the', 'times', 'i', 'knew', 'i', 'was', 'gay'], tags=['5']),\n",
       " TaggedDocument(words=['only', 'poet', 'and', 'other', 'stories'], tags=['6']),\n",
       " TaggedDocument(words=['shadow', 'dance'], tags=['7']),\n",
       " TaggedDocument(words=['one', 'night', 'new', 'york'], tags=['8']),\n",
       " TaggedDocument(words=['desert', 'children'], tags=['9']),\n",
       " TaggedDocument(words=['vindication', 'a', 'life', 'of', 'mary', 'wollstonecraft'], tags=['10']),\n",
       " TaggedDocument(words=['wounding', 'the', 'world'], tags=['11']),\n",
       " TaggedDocument(words=['mrs', 'palfrey', 'at', 'the', 'claremont'], tags=['12']),\n",
       " TaggedDocument(words=['the', 'observing', 'eye'], tags=['13']),\n",
       " TaggedDocument(words=['excellent', 'women'], tags=['14']),\n",
       " TaggedDocument(words=['excellent', 'women'], tags=['15']),\n",
       " TaggedDocument(words=['her', 'brilliant', 'career'], tags=['16']),\n",
       " TaggedDocument(words=['the', 'dud', 'avocado'], tags=['17']),\n",
       " TaggedDocument(words=['hester', 'lilly'], tags=['18']),\n",
       " TaggedDocument(words=['red', 'river', 'girl'], tags=['19']),\n",
       " TaggedDocument(words=['frenchman', 's', 'creek'], tags=['20']),\n",
       " TaggedDocument(words=['an', 'advent', 'calendar'], tags=['21']),\n",
       " TaggedDocument(words=['redhill', 'rococo'], tags=['22']),\n",
       " TaggedDocument(words=['selected', 'stories'], tags=['23']),\n",
       " TaggedDocument(words=['rebecca'], tags=['24']),\n",
       " TaggedDocument(words=['loitering', 'with', 'intent'], tags=['25']),\n",
       " TaggedDocument(words=['house', 'of', 'glass'], tags=['26']),\n",
       " TaggedDocument(words=['a', 'little', 'princess'], tags=['27']),\n",
       " TaggedDocument(words=['little', 'women'], tags=['28']),\n",
       " TaggedDocument(words=['marriage'], tags=['29']),\n",
       " TaggedDocument(words=['good', 'behaviour'], tags=['30']),\n",
       " TaggedDocument(words=['moral', 'disorder'], tags=['31']),\n",
       " TaggedDocument(words=['the', 'fox', 'at', 'the', 'manger'], tags=['32']),\n",
       " TaggedDocument(words=['the', 'daylight', 'and', 'the', 'dust', 'selected', 'short', 'stories'], tags=['33']),\n",
       " TaggedDocument(words=['chasm', 'a', 'weekend'], tags=['34']),\n",
       " TaggedDocument(words=['a', 'view', 'of', 'the', 'harbour'], tags=['35']),\n",
       " TaggedDocument(words=['the', 'diary', 'of', 'a', 'provincial', 'lady'], tags=['36']),\n",
       " TaggedDocument(words=['pomfret', 'towers'], tags=['37']),\n",
       " TaggedDocument(words=['tea', 'by', 'the', 'nursery', 'fire'], tags=['38']),\n",
       " TaggedDocument(words=['what', 'katy', 'did', 'at', 'school'], tags=['39']),\n",
       " TaggedDocument(words=['the', 'world', 's', 'smallest', 'unicorn', 'and', 'other', 'stories'], tags=['40']),\n",
       " TaggedDocument(words=['the', 'birds', 'and', 'other', 'stories'], tags=['41']),\n",
       " TaggedDocument(words=['angela', 'carter', 's', 'book', 'of', 'wayward', 'girls', 'and', 'wicked', 'women'], tags=['42']),\n",
       " TaggedDocument(words=['union', 'street'], tags=['43']),\n",
       " TaggedDocument(words=['nobody', 's', 'victim'], tags=['44']),\n",
       " TaggedDocument(words=['a', 'wreath', 'of', 'roses'], tags=['45']),\n",
       " TaggedDocument(words=['fingersmith'], tags=['46']),\n",
       " TaggedDocument(words=['something', 'was', 'there'], tags=['47']),\n",
       " TaggedDocument(words=['excellent', 'women', 'unlined', 'notebook'], tags=['48']),\n",
       " TaggedDocument(words=['valley', 'of', 'the', 'dolls'], tags=['49']),\n",
       " TaggedDocument(words=['good', 'behaviour'], tags=['50']),\n",
       " TaggedDocument(words=['good', 'behaviour'], tags=['51']),\n",
       " TaggedDocument(words=['walking', 'naked'], tags=['52']),\n",
       " TaggedDocument(words=['a', 'seat', 'at', 'the', 'table'], tags=['53']),\n",
       " TaggedDocument(words=['the', 'devastating', 'boys'], tags=['54']),\n",
       " TaggedDocument(words=['letters', 'from', 'egypt'], tags=['55']),\n",
       " TaggedDocument(words=['the', 'secret', 'diaries', 'of', 'miss', 'anne', 'lister', 'vol', '2'], tags=['56']),\n",
       " TaggedDocument(words=['lullaby', 'beach'], tags=['57']),\n",
       " TaggedDocument(words=['a', 'far', 'cry', 'from', 'kensington'], tags=['58']),\n",
       " TaggedDocument(words=['summer', 'half'], tags=['59']),\n",
       " TaggedDocument(words=['we', 'had', 'it', 'so', 'good'], tags=['60']),\n",
       " TaggedDocument(words=['if', 'not', 'winter', 'fragments', 'of', 'sappho'], tags=['61']),\n",
       " TaggedDocument(words=['angel'], tags=['62']),\n",
       " TaggedDocument(words=['the', 'secret', 'diaries', 'of', 'miss', 'anne', 'lister', 'vol', '1'], tags=['63']),\n",
       " TaggedDocument(words=['caldicott', 'place'], tags=['64']),\n",
       " TaggedDocument(words=['rebel', 'women'], tags=['65']),\n",
       " TaggedDocument(words=['good', 'wives'], tags=['66']),\n",
       " TaggedDocument(words=['the', 'seventh', 'cross'], tags=['67']),\n",
       " TaggedDocument(words=['the', 'bookseller', 'of', 'kabul'], tags=['68']),\n",
       " TaggedDocument(words=['maddaddam'], tags=['69']),\n",
       " TaggedDocument(words=['jane', 'of', 'lantern', 'hill'], tags=['70']),\n",
       " TaggedDocument(words=['angela', 'carter', 's', 'book', 'of', 'wayward', 'girls', 'and', 'wicked', 'women'], tags=['71']),\n",
       " TaggedDocument(words=['can', 'we', 'all', 'be', 'feminists'], tags=['72']),\n",
       " TaggedDocument(words=['small', 'g', 'a', 'summer', 'idyll'], tags=['73']),\n",
       " TaggedDocument(words=['sexual', 'anarchy'], tags=['74']),\n",
       " TaggedDocument(words=['anne', 'of', 'green', 'gables'], tags=['75']),\n",
       " TaggedDocument(words=['babies', 'in', 'rhinestones', 'and', 'other', 'stories'], tags=['76']),\n",
       " TaggedDocument(words=['anne', 'of', 'the', 'island'], tags=['77']),\n",
       " TaggedDocument(words=['the', 'artist', 's', 'widow'], tags=['78']),\n",
       " TaggedDocument(words=['the', 'vagina', 'monologues'], tags=['79']),\n",
       " TaggedDocument(words=['mandoa', 'mandoa'], tags=['80']),\n",
       " TaggedDocument(words=['surrogate'], tags=['81']),\n",
       " TaggedDocument(words=['the', 'sadeian', 'woman'], tags=['82']),\n",
       " TaggedDocument(words=['remember', 'remember'], tags=['83']),\n",
       " TaggedDocument(words=['peace', 'breaks', 'out'], tags=['84']),\n",
       " TaggedDocument(words=['confessions', 'of', 'a', 'failed', 'southern', 'lady'], tags=['85']),\n",
       " TaggedDocument(words=['liza', 's', 'england'], tags=['86']),\n",
       " TaggedDocument(words=['equal'], tags=['87']),\n",
       " TaggedDocument(words=['the', 'thoughtful', 'dresser'], tags=['88']),\n",
       " TaggedDocument(words=['the', 'temporary', 'bride'], tags=['89']),\n",
       " TaggedDocument(words=['the', 'turkish', 'embassy', 'letters'], tags=['90']),\n",
       " TaggedDocument(words=['rule', 'britannia'], tags=['91']),\n",
       " TaggedDocument(words=['the', 'passion', 'of', 'new', 'eve'], tags=['92']),\n",
       " TaggedDocument(words=['scenes', 'of', 'a', 'graphic', 'nature'], tags=['93']),\n",
       " TaggedDocument(words=['noel', 'streatfeild', 's', 'christmas', 'stories'], tags=['94']),\n",
       " TaggedDocument(words=['eva', 's', 'man'], tags=['95']),\n",
       " TaggedDocument(words=['wild', 'strawberries'], tags=['96']),\n",
       " TaggedDocument(words=['a', 'dog', 's', 'ransom'], tags=['97']),\n",
       " TaggedDocument(words=['the', 'ice', 'house'], tags=['98']),\n",
       " TaggedDocument(words=['in', 'the', 'full', 'light', 'of', 'the', 'sun'], tags=['99']),\n",
       " TaggedDocument(words=['crimson'], tags=['100']),\n",
       " TaggedDocument(words=['the', 'birds', 'and', 'other', 'stories'], tags=['101']),\n",
       " TaggedDocument(words=['the', 'magic', 'toyshop'], tags=['102']),\n",
       " TaggedDocument(words=['the', 'new', 'feminism'], tags=['103']),\n",
       " TaggedDocument(words=['lesbianism', 'made', 'easy'], tags=['104']),\n",
       " TaggedDocument(words=['anne', 'of', 'ingleside'], tags=['105']),\n",
       " TaggedDocument(words=['lolly', 'willowes'], tags=['106']),\n",
       " TaggedDocument(words=['living', 'dolls'], tags=['107']),\n",
       " TaggedDocument(words=['an', 'episode', 'of', 'sparrows'], tags=['108']),\n",
       " TaggedDocument(words=['emily', 's', 'quest'], tags=['109']),\n",
       " TaggedDocument(words=['outrages'], tags=['110']),\n",
       " TaggedDocument(words=['the', 'wind', 'in', 'my', 'hair'], tags=['111']),\n",
       " TaggedDocument(words=['angela', 'carter', 's', 'book', 'of', 'fairy', 'tales'], tags=['112']),\n",
       " TaggedDocument(words=['august', 'folly'], tags=['113']),\n",
       " TaggedDocument(words=['the', 'year', 'of', 'the', 'flood'], tags=['114']),\n",
       " TaggedDocument(words=['found', 'in', 'the', 'street'], tags=['115']),\n",
       " TaggedDocument(words=['the', 'crowded', 'street'], tags=['116']),\n",
       " TaggedDocument(words=['people', 'who', 'knock', 'on', 'the', 'door'], tags=['117']),\n",
       " TaggedDocument(words=['anne', 'of', 'the', 'island'], tags=['118']),\n",
       " TaggedDocument(words=['the', 'talented', 'mr', 'ripley'], tags=['119']),\n",
       " TaggedDocument(words=['high', 'rising'], tags=['120']),\n",
       " TaggedDocument(words=['strangers', 'on', 'a', 'train'], tags=['121']),\n",
       " TaggedDocument(words=['stone', 'mattress'], tags=['122']),\n",
       " TaggedDocument(words=['tipping', 'the', 'velvet'], tags=['123']),\n",
       " TaggedDocument(words=['hormonal'], tags=['124']),\n",
       " TaggedDocument(words=['that', 'lady'], tags=['125']),\n",
       " TaggedDocument(words=['a', 'stranger', 'city'], tags=['126']),\n",
       " TaggedDocument(words=['vagina'], tags=['127']),\n",
       " TaggedDocument(words=['mary', 'lavelle'], tags=['128']),\n",
       " TaggedDocument(words=['the', 'soul', 'of', 'kindness'], tags=['129']),\n",
       " TaggedDocument(words=['noel', 'streatfeild', 's', 'christmas', 'stories'], tags=['130']),\n",
       " TaggedDocument(words=['i', 'call', 'myself', 'a', 'feminist'], tags=['131']),\n",
       " TaggedDocument(words=['growing', 'up'], tags=['132']),\n",
       " TaggedDocument(words=['corregidora'], tags=['133']),\n",
       " TaggedDocument(words=['the', 'collected', 'stories', 'of', 'shirley', 'hazzard'], tags=['134']),\n",
       " TaggedDocument(words=['rebecca'], tags=['135']),\n",
       " TaggedDocument(words=['a', 'hundred', 'and', 'one', 'days'], tags=['136']),\n",
       " TaggedDocument(words=['the', 'seventh', 'cross'], tags=['137']),\n",
       " TaggedDocument(words=['i', 'know', 'why', 'the', 'caged', 'bird', 'sings'], tags=['138']),\n",
       " TaggedDocument(words=['the', 'orchard', 'on', 'fire'], tags=['139']),\n",
       " TaggedDocument(words=['a', 'thousand', 'days', 'in', 'tuscany'], tags=['140']),\n",
       " TaggedDocument(words=['vagina'], tags=['141']),\n",
       " TaggedDocument(words=['the', 'heart', 'goes', 'last'], tags=['142']),\n",
       " TaggedDocument(words=['mrs', 'palfrey', 'at', 'the', 'claremont'], tags=['143']),\n",
       " TaggedDocument(words=['orchids', 'on', 'your', 'budget'], tags=['144']),\n",
       " TaggedDocument(words=['an', 'unrestored', 'woman'], tags=['145']),\n",
       " TaggedDocument(words=['a', 'woman', 'of', 'my', 'age'], tags=['146']),\n",
       " TaggedDocument(words=['she', 'merchants', 'buccaneers', 'and', 'gentlewomen'], tags=['147']),\n",
       " TaggedDocument(words=['their', 'eyes', 'were', 'watching', 'god'], tags=['148']),\n",
       " TaggedDocument(words=['rebecca'], tags=['149']),\n",
       " TaggedDocument(words=['mad', 'bad', 'and', 'sad'], tags=['150']),\n",
       " TaggedDocument(words=['marling', 'hall'], tags=['151']),\n",
       " TaggedDocument(words=['the', 'street'], tags=['152']),\n",
       " TaggedDocument(words=['frost', 'in', 'may'], tags=['153']),\n",
       " TaggedDocument(words=['with', 'their', 'backs', 'to', 'the', 'world'], tags=['154']),\n",
       " TaggedDocument(words=['the', 'enchanted', 'april'], tags=['155']),\n",
       " TaggedDocument(words=['talented', 'mr', 'ripley', 'mug'], tags=['156']),\n",
       " TaggedDocument(words=['stone', 'mattress'], tags=['157']),\n",
       " TaggedDocument(words=['the', 'hidden', 'room'], tags=['158']),\n",
       " TaggedDocument(words=['frenchman', 's', 'creek'], tags=['159']),\n",
       " TaggedDocument(words=['what', 'are', 'we', 'doing', 'here'], tags=['160']),\n",
       " TaggedDocument(words=['angela', 'carter', 's', 'book', 'of', 'fairy', 'tales'], tags=['161']),\n",
       " TaggedDocument(words=['fingersmith'], tags=['162']),\n",
       " TaggedDocument(words=['the', 'diary', 'of', 'a', 'provincial', 'lady'], tags=['163']),\n",
       " TaggedDocument(words=['palladian'], tags=['164']),\n",
       " TaggedDocument(words=['the', 'dark', 'horse'], tags=['165']),\n",
       " TaggedDocument(words=['excellent', 'women'], tags=['166']),\n",
       " TaggedDocument(words=['the', 'birds', 'and', 'other', 'stories'], tags=['167']),\n",
       " TaggedDocument(words=['cheerfulness', 'breaks', 'in'], tags=['168']),\n",
       " TaggedDocument(words=['little', 'men'], tags=['169']),\n",
       " TaggedDocument(words=['divided', 'lives'], tags=['170']),\n",
       " TaggedDocument(words=['the', 'birds', 'on', 'the', 'trees'], tags=['171']),\n",
       " TaggedDocument(words=['women', 'who', 'wear', 'the', 'breeches'], tags=['172']),\n",
       " TaggedDocument(words=['the', 'collected', 'stories', 'of', 'grace', 'paley'], tags=['173']),\n",
       " TaggedDocument(words=['wave', 'me', 'goodbye'], tags=['174']),\n",
       " TaggedDocument(words=['the', 'last', 'of', 'summer'], tags=['175']),\n",
       " TaggedDocument(words=['peace', 'breaks', 'out'], tags=['176']),\n",
       " TaggedDocument(words=['talented', 'mr', 'ripley', 'notebook'], tags=['177']),\n",
       " TaggedDocument(words=['the', 'dark', 'circle'], tags=['178']),\n",
       " TaggedDocument(words=['talking', 'as', 'fast', 'as', 'i', 'can'], tags=['179']),\n",
       " TaggedDocument(words=['molly', 'keane'], tags=['180']),\n",
       " TaggedDocument(words=['anne', 's', 'house', 'of', 'dreams'], tags=['181']),\n",
       " TaggedDocument(words=['you', 're', 'on', 'an', 'airplane'], tags=['182']),\n",
       " TaggedDocument(words=['nobody', 'will', 'tell', 'you', 'this', 'but', 'me'], tags=['183']),\n",
       " TaggedDocument(words=['trans', 'like', 'me'], tags=['184']),\n",
       " TaggedDocument(words=['heartburn'], tags=['185']),\n",
       " TaggedDocument(words=['radical', 'hope'], tags=['186']),\n",
       " TaggedDocument(words=['between', 'the', 'stops'], tags=['187']),\n",
       " TaggedDocument(words=['cheerfulness', 'breaks', 'in'], tags=['188']),\n",
       " TaggedDocument(words=['new', 'treasure', 'seekers'], tags=['189']),\n",
       " TaggedDocument(words=['the', 'virago', 'book', 'of', 'witches'], tags=['190']),\n",
       " TaggedDocument(words=['dreams', 'of', 'dead', 'women', 's', 'handbags'], tags=['191']),\n",
       " TaggedDocument(words=['valley', 'of', 'the', 'dolls'], tags=['192']),\n",
       " TaggedDocument(words=['the', 'tortoise', 'and', 'the', 'hare'], tags=['193']),\n",
       " TaggedDocument(words=['one', 'pair', 'of', 'feet'], tags=['194']),\n",
       " TaggedDocument(words=['i', 'know', 'why', 'the', 'caged', 'bird', 'sings'], tags=['195']),\n",
       " TaggedDocument(words=['what', 'it', 'means', 'to', 'be', 'human'], tags=['196']),\n",
       " TaggedDocument(words=['hormonal'], tags=['197']),\n",
       " TaggedDocument(words=['two', 'trees', 'make', 'a', 'forest'], tags=['198']),\n",
       " TaggedDocument(words=['memento', 'mori'], tags=['199']),\n",
       " TaggedDocument(words=['what', 'are', 'you', 'going', 'through'], tags=['200']),\n",
       " TaggedDocument(words=['the', 'passion', 'of', 'new', 'eve'], tags=['201']),\n",
       " TaggedDocument(words=['molly', 'keane'], tags=['202']),\n",
       " TaggedDocument(words=['a', 'little', 'love', 'a', 'little', 'learning'], tags=['203']),\n",
       " TaggedDocument(words=['rilla', 'of', 'ingleside'], tags=['204']),\n",
       " TaggedDocument(words=['mrs', 'palfrey', 'at', 'the', 'claremont'], tags=['205']),\n",
       " TaggedDocument(words=['turning'], tags=['206']),\n",
       " TaggedDocument(words=['vanishing', 'cornwall'], tags=['207']),\n",
       " TaggedDocument(words=['the', 'world', 'my', 'wilderness'], tags=['208']),\n",
       " TaggedDocument(words=['shadow', 'dance'], tags=['209']),\n",
       " TaggedDocument(words=['rainbow', 'valley'], tags=['210']),\n",
       " TaggedDocument(words=['the', 'last', 'of', 'her', 'kind'], tags=['211']),\n",
       " TaggedDocument(words=['woman'], tags=['212']),\n",
       " TaggedDocument(words=['in', 'the', 'full', 'light', 'of', 'the', 'sun'], tags=['213']),\n",
       " TaggedDocument(words=['between', 'the', 'stops'], tags=['214']),\n",
       " TaggedDocument(words=['rebecca'], tags=['215']),\n",
       " TaggedDocument(words=['new', 'treasure', 'seekers'], tags=['216']),\n",
       " TaggedDocument(words=['wave'], tags=['217']),\n",
       " TaggedDocument(words=['caldicott', 'place'], tags=['218']),\n",
       " TaggedDocument(words=['suffragettes'], tags=['219']),\n",
       " TaggedDocument(words=['the', 'loving', 'spirit'], tags=['220']),\n",
       " TaggedDocument(words=['the', 'ice', 'house'], tags=['221']),\n",
       " TaggedDocument(words=['don', 't', 'look', 'now', 'and', 'other', 'stories'], tags=['222']),\n",
       " TaggedDocument(words=['a', 'game', 'of', 'hide', 'and', 'seek'], tags=['223']),\n",
       " TaggedDocument(words=['the', 'wind', 'in', 'my', 'hair'], tags=['224']),\n",
       " TaggedDocument(words=['a', 'stranger', 'city'], tags=['225']),\n",
       " TaggedDocument(words=['magic', 'toyshop', 'mug'], tags=['226']),\n",
       " TaggedDocument(words=['dangerous', 'calm'], tags=['227']),\n",
       " TaggedDocument(words=['still', 'here'], tags=['228']),\n",
       " TaggedDocument(words=['a', 'game', 'of', 'hide', 'and', 'seek'], tags=['229']),\n",
       " TaggedDocument(words=['the', 'wedding', 'group'], tags=['230']),\n",
       " TaggedDocument(words=['can', 'we', 'all', 'be', 'feminists'], tags=['231']),\n",
       " TaggedDocument(words=['how', 'a', 'woman', 'becomes', 'a', 'lake'], tags=['232']),\n",
       " TaggedDocument(words=['magic', 'toyshop', 'notebook'], tags=['233']),\n",
       " TaggedDocument(words=['anne', 'of', 'windy', 'willows'], tags=['234']),\n",
       " TaggedDocument(words=['radical', 'help'], tags=['235']),\n",
       " TaggedDocument(words=['the', 'people', 'on', 'the', 'street', 'a', 'writer', 's', 'view', 'of', 'israel'], tags=['236']),\n",
       " TaggedDocument(words=['blow', 'your', 'house', 'down'], tags=['237']),\n",
       " TaggedDocument(words=['eve', 'and', 'the', 'new', 'jerusalem'], tags=['238']),\n",
       " TaggedDocument(words=['i', 'call', 'myself', 'a', 'feminist'], tags=['239']),\n",
       " TaggedDocument(words=['the', 'cast', 'iron', 'shore'], tags=['240']),\n",
       " TaggedDocument(words=['the', 'wedding'], tags=['241']),\n",
       " TaggedDocument(words=['before', 'lunch'], tags=['242']),\n",
       " TaggedDocument(words=['jamaica', 'inn'], tags=['243']),\n",
       " TaggedDocument(words=['jamaica', 'inn'], tags=['244']),\n",
       " TaggedDocument(words=['invisible', 'thread'], tags=['245']),\n",
       " TaggedDocument(words=['christmas', 'at', 'high', 'rising'], tags=['246']),\n",
       " TaggedDocument(words=['how', 'a', 'woman', 'becomes', 'a', 'lake'], tags=['247']),\n",
       " TaggedDocument(words=['death', 'goes', 'on', 'skis'], tags=['248']),\n",
       " TaggedDocument(words=['a', 'game', 'for', 'the', 'living'], tags=['249']),\n",
       " TaggedDocument(words=['the', 'unpassing'], tags=['250']),\n",
       " TaggedDocument(words=['the', 'collected', 'stories', 'of', 'grace', 'paley'], tags=['251']),\n",
       " TaggedDocument(words=['several', 'perceptions'], tags=['252']),\n",
       " TaggedDocument(words=['the', 'brandons'], tags=['253']),\n",
       " TaggedDocument(words=['the', 'return', 'of', 'the', 'soldier'], tags=['254']),\n",
       " TaggedDocument(words=['stranger', 'on', 'a', 'train'], tags=['255']),\n",
       " TaggedDocument(words=['border', 'crossing'], tags=['256']),\n",
       " TaggedDocument(words=['i', 'was', 'told', 'to', 'come', 'alone'], tags=['257']),\n",
       " TaggedDocument(words=['west', 'with', 'the', 'night'], tags=['258']),\n",
       " TaggedDocument(words=['a', 'feather', 'on', 'the', 'breath', 'of', 'god'], tags=['259']),\n",
       " TaggedDocument(words=['nothing', 'sacred'], tags=['260']),\n",
       " TaggedDocument(words=['the', 'land', 'of', 'green', 'ginger'], tags=['261']),\n",
       " TaggedDocument(words=['jack'], tags=['262']),\n",
       " TaggedDocument(words=['a', 'woman', 'in', 'berlin'], tags=['263']),\n",
       " TaggedDocument(words=['trials', 'of', 'passion'], tags=['264']),\n",
       " TaggedDocument(words=['anne', 'of', 'avonlea'], tags=['265']),\n",
       " TaggedDocument(words=['crewe', 'train'], tags=['266']),\n",
       " TaggedDocument(words=['the', 'clothes', 'on', 'their', 'backs'], tags=['267']),\n",
       " TaggedDocument(words=['growing', 'up'], tags=['268']),\n",
       " TaggedDocument(words=['a', 'view', 'of', 'the', 'harbour'], tags=['269']),\n",
       " TaggedDocument(words=['the', 'women', 's', 'room'], tags=['270']),\n",
       " TaggedDocument(words=['good', 'behaviour', 'unlined', 'notebook'], tags=['271']),\n",
       " TaggedDocument(words=['upstairs', 'at', 'the', 'party'], tags=['272']),\n",
       " TaggedDocument(words=['poor', 'caroline'], tags=['273']),\n",
       " TaggedDocument(words=['the', 'atmospheric', 'railway'], tags=['274']),\n",
       " TaggedDocument(words=['jo', 's', 'boys'], tags=['275']),\n",
       " TaggedDocument(words=['the', 'headmistress'], tags=['276']),\n",
       " TaggedDocument(words=['the', 'age', 'of', 'innocence'], tags=['277']),\n",
       " TaggedDocument(words=['paris', 'was', 'yesterday'], tags=['278']),\n",
       " TaggedDocument(words=['singin', 'swingin', 'and', 'gettin', 'merry', 'like', 'christmas'], tags=['279']),\n",
       " TaggedDocument(words=['the', 'magic', 'toyshop'], tags=['280']),\n",
       " TaggedDocument(words=['owls', 'do', 'cry'], tags=['281']),\n",
       " TaggedDocument(words=['the', 'cast', 'iron', 'shore'], tags=['282']),\n",
       " TaggedDocument(words=['the', 'secret', 'garden'], tags=['283']),\n",
       " TaggedDocument(words=['once', 'upon', 'a', 'time', 'there', 'was', 'a', 'traveller'], tags=['284']),\n",
       " TaggedDocument(words=['fire', 'from', 'heaven'], tags=['285']),\n",
       " TaggedDocument(words=['a', 'woman', 'of', 'no', 'importance'], tags=['286']),\n",
       " TaggedDocument(words=['south', 'riding'], tags=['287']),\n",
       " TaggedDocument(words=['anderby', 'wold'], tags=['288']),\n",
       " TaggedDocument(words=['a', 'little', 'princess'], tags=['289']),\n",
       " TaggedDocument(words=['you', 'are', 'always', 'with', 'me'], tags=['290']),\n",
       " TaggedDocument(words=['a', 'woman', 'of', 'no', 'importance'], tags=['291']),\n",
       " TaggedDocument(words=['the', 'sadeian', 'woman'], tags=['292']),\n",
       " TaggedDocument(words=['rebecca'], tags=['293']),\n",
       " TaggedDocument(words=['the', 'temporary', 'bride'], tags=['294']),\n",
       " TaggedDocument(words=['mary', 'lavelle'], tags=['295']),\n",
       " TaggedDocument(words=['testament', 'of', 'youth'], tags=['296']),\n",
       " TaggedDocument(words=['the', 'secret', 'garden'], tags=['297']),\n",
       " TaggedDocument(words=['dancing', 'on', 'the', 'outskirts'], tags=['298']),\n",
       " TaggedDocument(words=['their', 'eyes', 'were', 'watching', 'god'], tags=['299']),\n",
       " TaggedDocument(words=['apple', 'bough'], tags=['300']),\n",
       " TaggedDocument(words=['deep', 'water'], tags=['301']),\n",
       " TaggedDocument(words=['the', 'ante', 'room'], tags=['302']),\n",
       " TaggedDocument(words=['two', 'trees', 'make', 'a', 'forest'], tags=['303']),\n",
       " TaggedDocument(words=['the', 'brink', 'of', 'being'], tags=['304']),\n",
       " TaggedDocument(words=['the', 'tortoise', 'and', 'the', 'hare'], tags=['305']),\n",
       " TaggedDocument(words=['jamaica', 'inn'], tags=['306']),\n",
       " TaggedDocument(words=['i', 'might', 'regret', 'this'], tags=['307']),\n",
       " TaggedDocument(words=['complete', 'short', 'stories'], tags=['308']),\n",
       " TaggedDocument(words=['anne', 's', 'house', 'of', 'dreams'], tags=['309']),\n",
       " TaggedDocument(words=['lullaby', 'beach'], tags=['310']),\n",
       " TaggedDocument(words=['without', 'my', 'cloak'], tags=['311']),\n",
       " TaggedDocument(words=['emily', 'climbs'], tags=['312']),\n",
       " TaggedDocument(words=['rape', 'a', 'history', 'from', '1860', 'to', 'the', 'present'], tags=['313']),\n",
       " TaggedDocument(words=['rebel', 'girls'], tags=['314']),\n",
       " TaggedDocument(words=['how', 'a', 'woman', 'becomes', 'a', 'lake'], tags=['315']),\n",
       " TaggedDocument(words=['dr', 'clock', 's', 'last', 'case'], tags=['316']),\n",
       " TaggedDocument(words=['a', 'view', 'of', 'the', 'harbour'], tags=['317']),\n",
       " TaggedDocument(words=['blaming'], tags=['318']),\n",
       " TaggedDocument(words=['what', 'katy', 'did'], tags=['319']),\n",
       " TaggedDocument(words=['owls', 'do', 'cry'], tags=['320']),\n",
       " TaggedDocument(words=['at', 'mrs', 'lippincote', 's'], tags=['321']),\n",
       " TaggedDocument(words=['miss', 'bunting'], tags=['322']),\n",
       " TaggedDocument(words=['noel', 'streatfeild', 's', 'christmas', 'stories'], tags=['323']),\n",
       " TaggedDocument(words=['corregidora'], tags=['324']),\n",
       " TaggedDocument(words=['the', 'enchanted', 'april'], tags=['325']),\n",
       " TaggedDocument(words=['the', 'angel', 'of', 'grozny'], tags=['326']),\n",
       " TaggedDocument(words=['nothing', 'sacred'], tags=['327']),\n",
       " TaggedDocument(words=['the', 'land', 'of', 'spices'], tags=['328']),\n",
       " TaggedDocument(words=['the', 'people', 'on', 'the', 'street', 'a', 'writer', 's', 'view', 'of', 'israel'], tags=['329']),\n",
       " TaggedDocument(words=['outsiders'], tags=['330']),\n",
       " TaggedDocument(words=['dunedin'], tags=['331']),\n",
       " TaggedDocument(words=['i', 'might', 'regret', 'this'], tags=['332']),\n",
       " TaggedDocument(words=['the', 'dud', 'avocado'], tags=['333']),\n",
       " TaggedDocument(words=['strangers', 'on', 'a', 'train'], tags=['334']),\n",
       " TaggedDocument(words=['faces', 'in', 'the', 'water'], tags=['335']),\n",
       " TaggedDocument(words=['good', 'behaviour', 'mug'], tags=['336']),\n",
       " TaggedDocument(words=['nobody', 's', 'victim'], tags=['337']),\n",
       " TaggedDocument(words=['whole', 'of', 'a', 'morning', 'sky'], tags=['338']),\n",
       " TaggedDocument(words=['the', 'dud', 'avocado'], tags=['339']),\n",
       " TaggedDocument(words=['black', 'narcissus'], tags=['340']),\n",
       " TaggedDocument(words=['northbridge', 'rectory'], tags=['341']),\n",
       " TaggedDocument(words=['the', 'talented', 'mr', 'ripley'], tags=['342']),\n",
       " TaggedDocument(words=['harriet', 'said'], tags=['343']),\n",
       " TaggedDocument(words=['all', 'of', 'us', 'there'], tags=['344']),\n",
       " TaggedDocument(words=['a', 'bowl', 'of', 'cherries'], tags=['345']),\n",
       " TaggedDocument(words=['listen', 'to', 'the', 'nightingale'], tags=['346']),\n",
       " TaggedDocument(words=['death', 'goes', 'on', 'skis'], tags=['347']),\n",
       " TaggedDocument(words=['a', 'lady', 's', 'life', 'in', 'the', 'rocky', 'mountains'], tags=['348']),\n",
       " TaggedDocument(words=['the', 'year', 'of', 'the', 'flood'], tags=['349']),\n",
       " TaggedDocument(words=['several', 'perceptions'], tags=['350']),\n",
       " TaggedDocument(words=['the', 'weather', 'in', 'the', 'streets'], tags=['351']),\n",
       " TaggedDocument(words=['the', 'laughing', 'academy'], tags=['352']),\n",
       " TaggedDocument(words=['afternoon', 'of', 'a', 'good', 'woman'], tags=['353']),\n",
       " TaggedDocument(words=['what', 'katy', 'did', 'next'], tags=['354']),\n",
       " TaggedDocument(words=['love', 'like', 'salt'], tags=['355']),\n",
       " TaggedDocument(words=['the', 'magic', 'toyshop'], tags=['356']),\n",
       " TaggedDocument(words=['in', 'a', 'summer', 'season'], tags=['357']),\n",
       " TaggedDocument(words=['chasm', 'a', 'weekend'], tags=['358']),\n",
       " TaggedDocument(words=['don', 't', 'look', 'now', 'and', 'other', 'stories'], tags=['359']),\n",
       " TaggedDocument(words=['the', 'world', 'my', 'wilderness'], tags=['360'])]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ba46885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:43:16: Doc2Vec lifecycle event {'params': 'Doc2Vec(dbow,d50,n5,mc5,s0.001,t3)', 'datetime': '2021-11-05T16:43:16.124758', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-5.10.0-8-amd64-x86_64-with-glibc2.10', 'event': 'created'}\n",
      "INFO - 16:43:16: collecting all words and their counts\n",
      "INFO - 16:43:16: PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "INFO - 16:43:16: collected 535 word types and 361 unique tags from a corpus of 361 examples and 1300 words\n",
      "INFO - 16:43:16: Creating a fresh vocabulary\n",
      "INFO - 16:43:16: Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 32 unique words (5.981308411214953%% of original 535, drops 503)', 'datetime': '2021-11-05T16:43:16.408996', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-5.10.0-8-amd64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 16:43:16: Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 510 word corpus (39.23076923076923%% of original 1300, drops 790)', 'datetime': '2021-11-05T16:43:16.409739', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-5.10.0-8-amd64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 16:43:16: deleting the raw counts dictionary of 535 items\n",
      "INFO - 16:43:16: sample=0.001 downsamples 32 most-common words\n",
      "INFO - 16:43:16: Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 94.85875347795753 word corpus (18.6%% of prior 510)', 'datetime': '2021-11-05T16:43:16.412470', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-5.10.0-8-amd64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 16:43:16: estimated required memory for 32 words and 50 dimensions: 173200 bytes\n",
      "INFO - 16:43:16: resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(vector_size=50, min_count = 5, epochs = 25, dm = 0)\n",
    "model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40377d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:43:28: Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 32 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5', 'datetime': '2021-11-05T16:43:28.648704', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-5.10.0-8-amd64-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 1 : training on 1300 raw words (449 effective words) took 0.0s, 16136 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 2 : training on 1300 raw words (459 effective words) took 0.0s, 23493 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 3 : training on 1300 raw words (450 effective words) took 0.0s, 26627 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 4 : training on 1300 raw words (456 effective words) took 0.0s, 27241 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 5 : training on 1300 raw words (467 effective words) took 0.0s, 32187 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 6 : training on 1300 raw words (448 effective words) took 0.0s, 26150 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 7 : training on 1300 raw words (459 effective words) took 0.0s, 31241 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 8 : training on 1300 raw words (449 effective words) took 0.0s, 30995 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 9 : training on 1300 raw words (440 effective words) took 0.0s, 33523 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 10 : training on 1300 raw words (452 effective words) took 0.0s, 27636 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 11 : training on 1300 raw words (461 effective words) took 0.0s, 33291 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 12 : training on 1300 raw words (467 effective words) took 0.0s, 27170 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 13 : training on 1300 raw words (453 effective words) took 0.0s, 34002 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 14 : training on 1300 raw words (447 effective words) took 0.0s, 31543 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:28: EPOCH - 15 : training on 1300 raw words (445 effective words) took 0.0s, 31235 effective words/s\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:29: EPOCH - 16 : training on 1300 raw words (461 effective words) took 0.0s, 33558 effective words/s\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:29: EPOCH - 17 : training on 1300 raw words (456 effective words) took 0.0s, 30285 effective words/s\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:29: EPOCH - 18 : training on 1300 raw words (465 effective words) took 0.0s, 32251 effective words/s\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:29: EPOCH - 19 : training on 1300 raw words (454 effective words) took 0.0s, 25416 effective words/s\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:29: EPOCH - 20 : training on 1300 raw words (451 effective words) took 0.0s, 33232 effective words/s\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:29: EPOCH - 21 : training on 1300 raw words (455 effective words) took 0.0s, 25908 effective words/s\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:29: EPOCH - 22 : training on 1300 raw words (450 effective words) took 0.0s, 26000 effective words/s\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:29: EPOCH - 23 : training on 1300 raw words (460 effective words) took 0.0s, 34691 effective words/s\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:43:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:29: EPOCH - 24 : training on 1300 raw words (467 effective words) took 0.0s, 30998 effective words/s\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 16:43:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 16:43:29: EPOCH - 25 : training on 1300 raw words (443 effective words) took 0.0s, 30507 effective words/s\n",
      "INFO - 16:43:29: Doc2Vec lifecycle event {'msg': 'training on 32500 raw words (11364 effective words) took 0.6s, 20535 effective words/s', 'datetime': '2021-11-05T16:43:29.204722', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-5.10.0-8-amd64-x86_64-with-glibc2.10', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3799c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4f6e0c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.5230412e-03  3.4986853e-04  6.6339254e-04 -6.2449425e-03\n",
      "  1.3779759e-03 -9.4274487e-03 -9.5011564e-03  4.5402693e-03\n",
      "  2.1843684e-03  9.4820894e-03  8.9704348e-03  7.0758569e-03\n",
      " -8.4697092e-03  1.7201054e-03  4.5998096e-03  4.9362779e-03\n",
      " -4.4988929e-03 -4.5277732e-03  1.5663696e-03 -2.0434863e-03\n",
      "  1.3189912e-03 -3.4254438e-03  7.4231671e-03  4.6300887e-05\n",
      " -7.6287319e-03  6.5903380e-03 -5.8929259e-03  8.4285606e-03\n",
      "  2.9216863e-03  9.7406302e-03  9.4274487e-03 -7.3194527e-03\n",
      " -5.2250517e-03  9.4598054e-04  4.7107125e-03 -6.9367541e-03\n",
      "  4.8315167e-04 -1.9679822e-03  2.5304032e-03  3.8994825e-03\n",
      "  4.6591139e-03 -2.4499565e-03 -4.4073150e-03  7.7767670e-03\n",
      "  5.6682886e-03 -6.5937019e-03 -9.2968056e-03 -4.1475324e-03\n",
      "  4.1884435e-03 -6.0530538e-03]\n"
     ]
    }
   ],
   "source": [
    "book_vector = model.infer_vector(df_clean['name'])\n",
    "print(book_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05ec7733",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviePath = path + 'Movie/All/'\n",
    "movieFilenames = next(walk(moviePath), (None, None, []))[2]\n",
    "\n",
    "movieData = []\n",
    "\n",
    "for movie in movieFilenames[:5]:\n",
    "    with gzip.open(moviePath + movie, 'r') as dataFile:\n",
    "        for line in dataFile:\n",
    "            lineData = json.loads(line.decode('utf-8'))\n",
    "            movieData.append(lineData)\n",
    "movieDF = pd.DataFrame(movieData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "36c0f1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>director</th>\n",
       "      <th>duration</th>\n",
       "      <th>genre</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "      <th>page_url</th>\n",
       "      <th>aggregaterating</th>\n",
       "      <th>ratingvalue</th>\n",
       "      <th>datecreated</th>\n",
       "      <th>actors</th>\n",
       "      <th>author</th>\n",
       "      <th>datemodified</th>\n",
       "      <th>datepublished</th>\n",
       "      <th>image</th>\n",
       "      <th>keywords</th>\n",
       "      <th>creator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Beast No More (2019)</td>\n",
       "      <td>Beast No More 123movies Watch Online Streaming...</td>\n",
       "      <td>Aaron Warwick</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[Horror, Thriller]</td>\n",
       "      <td>https://123moviesfx.com/beast-no-more/</td>\n",
       "      <td>Hello, Little Lamb. Mary Jane's Got a New Son.</td>\n",
       "      <td>https://123moviesfx.com/beast-no-more/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Superman: Man of Tomorrow (2020)</td>\n",
       "      <td>Superman: Man of Tomorrow 123movies Watch Onli...</td>\n",
       "      <td>Chris Palmer</td>\n",
       "      <td>86 min</td>\n",
       "      <td>[Science Fiction, Animation, Action]</td>\n",
       "      <td>https://123moviesfx.com/superman-man-of-tomorrow/</td>\n",
       "      <td>Before he was the Man of Steel, he was the Man...</td>\n",
       "      <td>https://123moviesfx.com/superman-man-of-tomorrow/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Discarded (2020)</td>\n",
       "      <td>The Discarded 123movies Watch Online Streaming...</td>\n",
       "      <td>Piotr Skowronski</td>\n",
       "      <td>86 min</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>https://123moviesfx.com/the-discarded/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://123moviesfx.com/the-discarded/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Souvenirs (2020)</td>\n",
       "      <td>Souvenirs 123movies Watch Online Streaming Fre...</td>\n",
       "      <td>Anna Mikami</td>\n",
       "      <td>84 min</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>https://123moviesfx.com/souvenirs/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://123moviesfx.com/souvenirs/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Robot Riot (2020)</td>\n",
       "      <td>Robot Riot 123movies Watch Online Streaming Fr...</td>\n",
       "      <td>Ryan Staples Scott</td>\n",
       "      <td>88 min</td>\n",
       "      <td>[Science Fiction, Action]</td>\n",
       "      <td>https://123moviesfx.com/robot-riot/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://123moviesfx.com/robot-riot/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                              name  \\\n",
       "0       0              Beast No More (2019)   \n",
       "1       1  Superman: Man of Tomorrow (2020)   \n",
       "2       2              The Discarded (2020)   \n",
       "3       3                  Souvenirs (2020)   \n",
       "4       4                 Robot Riot (2020)   \n",
       "\n",
       "                                         description            director  \\\n",
       "0  Beast No More 123movies Watch Online Streaming...       Aaron Warwick   \n",
       "1  Superman: Man of Tomorrow 123movies Watch Onli...        Chris Palmer   \n",
       "2  The Discarded 123movies Watch Online Streaming...    Piotr Skowronski   \n",
       "3  Souvenirs 123movies Watch Online Streaming Fre...         Anna Mikami   \n",
       "4  Robot Riot 123movies Watch Online Streaming Fr...  Ryan Staples Scott   \n",
       "\n",
       "  duration                                 genre  \\\n",
       "0      N/A                    [Horror, Thriller]   \n",
       "1   86 min  [Science Fiction, Animation, Action]   \n",
       "2   86 min                              Thriller   \n",
       "3   84 min                              Thriller   \n",
       "4   88 min             [Science Fiction, Action]   \n",
       "\n",
       "                                                 url  \\\n",
       "0             https://123moviesfx.com/beast-no-more/   \n",
       "1  https://123moviesfx.com/superman-man-of-tomorrow/   \n",
       "2             https://123moviesfx.com/the-discarded/   \n",
       "3                 https://123moviesfx.com/souvenirs/   \n",
       "4                https://123moviesfx.com/robot-riot/   \n",
       "\n",
       "                                            headline  \\\n",
       "0     Hello, Little Lamb. Mary Jane's Got a New Son.   \n",
       "1  Before he was the Man of Steel, he was the Man...   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                            page_url aggregaterating  \\\n",
       "0             https://123moviesfx.com/beast-no-more/             NaN   \n",
       "1  https://123moviesfx.com/superman-man-of-tomorrow/             NaN   \n",
       "2             https://123moviesfx.com/the-discarded/             NaN   \n",
       "3                 https://123moviesfx.com/souvenirs/             NaN   \n",
       "4                https://123moviesfx.com/robot-riot/             NaN   \n",
       "\n",
       "  ratingvalue datecreated actors author datemodified datepublished image  \\\n",
       "0         NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "1         NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "2         NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "3         NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "4         NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "\n",
       "  keywords creator  \n",
       "0      NaN     NaN  \n",
       "1      NaN     NaN  \n",
       "2      NaN     NaN  \n",
       "3      NaN     NaN  \n",
       "4      NaN     NaN  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3d31cd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1334.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>273.912294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>239.049548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>179.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>465.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>799.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id\n",
       "count  1334.000000\n",
       "mean    273.912294\n",
       "std     239.049548\n",
       "min       0.000000\n",
       "25%      72.000000\n",
       "50%     179.000000\n",
       "75%     465.750000\n",
       "max     799.000000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3a963dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_empty_rows(df):\n",
    "    rows = []\n",
    "    for i, row in enumerate(df['name']):\n",
    "        if type(row) != str:\n",
    "            rows.append(i)\n",
    "    df_clean = df.drop(index=rows)\n",
    "    df_clean = df_clean.reset_index(drop=True)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b9fe0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_clean = delete_empty_rows(movieDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d58b202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1203.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>293.916043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>242.855579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>498.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>799.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id\n",
       "count  1203.000000\n",
       "mean    293.916043\n",
       "std     242.855579\n",
       "min       0.000000\n",
       "25%      77.000000\n",
       "50%     210.000000\n",
       "75%     498.500000\n",
       "max     799.000000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4ce62381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-f758b1c2d86d>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"new_column\"] = df['name'].str.replace('[^\\w\\s]', ' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>director</th>\n",
       "      <th>duration</th>\n",
       "      <th>genre</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "      <th>page_url</th>\n",
       "      <th>aggregaterating</th>\n",
       "      <th>ratingvalue</th>\n",
       "      <th>datecreated</th>\n",
       "      <th>actors</th>\n",
       "      <th>author</th>\n",
       "      <th>datemodified</th>\n",
       "      <th>datepublished</th>\n",
       "      <th>image</th>\n",
       "      <th>keywords</th>\n",
       "      <th>creator</th>\n",
       "      <th>new_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Beast No More (2019)</td>\n",
       "      <td>Beast No More 123movies Watch Online Streaming...</td>\n",
       "      <td>Aaron Warwick</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[Horror, Thriller]</td>\n",
       "      <td>https://123moviesfx.com/beast-no-more/</td>\n",
       "      <td>Hello, Little Lamb. Mary Jane's Got a New Son.</td>\n",
       "      <td>https://123moviesfx.com/beast-no-more/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beast No More  2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Superman: Man of Tomorrow (2020)</td>\n",
       "      <td>Superman: Man of Tomorrow 123movies Watch Onli...</td>\n",
       "      <td>Chris Palmer</td>\n",
       "      <td>86 min</td>\n",
       "      <td>[Science Fiction, Animation, Action]</td>\n",
       "      <td>https://123moviesfx.com/superman-man-of-tomorrow/</td>\n",
       "      <td>Before he was the Man of Steel, he was the Man...</td>\n",
       "      <td>https://123moviesfx.com/superman-man-of-tomorrow/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Superman  Man of Tomorrow  2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Discarded (2020)</td>\n",
       "      <td>The Discarded 123movies Watch Online Streaming...</td>\n",
       "      <td>Piotr Skowronski</td>\n",
       "      <td>86 min</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>https://123moviesfx.com/the-discarded/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://123moviesfx.com/the-discarded/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Discarded  2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Souvenirs (2020)</td>\n",
       "      <td>Souvenirs 123movies Watch Online Streaming Fre...</td>\n",
       "      <td>Anna Mikami</td>\n",
       "      <td>84 min</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>https://123moviesfx.com/souvenirs/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://123moviesfx.com/souvenirs/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Souvenirs  2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Robot Riot (2020)</td>\n",
       "      <td>Robot Riot 123movies Watch Online Streaming Fr...</td>\n",
       "      <td>Ryan Staples Scott</td>\n",
       "      <td>88 min</td>\n",
       "      <td>[Science Fiction, Action]</td>\n",
       "      <td>https://123moviesfx.com/robot-riot/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://123moviesfx.com/robot-riot/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robot Riot  2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>40</td>\n",
       "      <td>Bill &amp; Ted Face the Music (2020) Full Movie</td>\n",
       "      <td>Watch Bill &amp; Ted Face the Music (2020) : Full ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Comedy, Comedy, Science Fiction, Adventure, S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://megacinema21.com/movie/501979/bill-ted-...</td>\n",
       "      <td>[{'ratingvalue': '4.7', 'worstrating': '1', 'r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'Gypsy'}, {'name': 'Ling Lun'}, {'na...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-27</td>\n",
       "      <td>https://image.tmdb.org/t/p/original/oazPqs1z78...</td>\n",
       "      <td>[music, guitar, time travel, music, sequel, fa...</td>\n",
       "      <td>[{'name': 'United States of America'}, {'name'...</td>\n",
       "      <td>Bill   Ted Face the Music  2020  Full Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>41</td>\n",
       "      <td>Mulan (2020) Full Movie</td>\n",
       "      <td>Watch Mulan (2020) : Full Movie Online Free Wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[War, Drama, Adventure, Drama, Action, War, Fa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://megacinema21.com/movie/337401/mulan.html</td>\n",
       "      <td>[{'ratingvalue': '4.7', 'worstrating': '1', 'r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'The Chancellor'}, {'name': 'Bati Te...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-10</td>\n",
       "      <td>https://image.tmdb.org/t/p/original/pbAszLhGyW...</td>\n",
       "      <td>[costumes, courage, honor, martial arts, heroi...</td>\n",
       "      <td>[{'name': 'Walt Disney Pictures, China Film Gr...</td>\n",
       "      <td>Mulan  2020  Full Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>42</td>\n",
       "      <td>Rambo: Last Blood (2019) Full Movie</td>\n",
       "      <td>Watch Rambo: Last Blood (2019) : Full Movie On...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Thriller, Drama, Action, Thriller, Drama, Act...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://megacinema21.com/movie/522938/rambo-las...</td>\n",
       "      <td>[{'ratingvalue': '4.7', 'worstrating': '1', 'r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'Doctor Sergio'}, {'name': 'Bouncer'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>https://image.tmdb.org/t/p/original/iJtcxqrWDf...</td>\n",
       "      <td>[mexican american border, human trafficking, s...</td>\n",
       "      <td>[{'name': 'Millennium Films, Balboa Production...</td>\n",
       "      <td>Rambo  Last Blood  2019  Full Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>43</td>\n",
       "      <td>The Good Liar (2019) Full Movie</td>\n",
       "      <td>Watch The Good Liar (2019) : Full Movie Online...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Mystery, Drama, Crime, Drama, Mystery, Crime]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://megacinema21.com/movie/511322/the-good-...</td>\n",
       "      <td>[{'ratingvalue': '4.7', 'worstrating': '1', 'r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'Steven'}, {'name': 'Vincent'}, {'na...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-08</td>\n",
       "      <td>https://image.tmdb.org/t/p/original/du6TQLtjXH...</td>\n",
       "      <td>[based on novel or book, based on novel or boo...</td>\n",
       "      <td>[{'name': 'Germany, United Kingdom, United Sta...</td>\n",
       "      <td>The Good Liar  2019  Full Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>44</td>\n",
       "      <td>Tenet (2020) Full Movie</td>\n",
       "      <td>Watch Tenet (2020) : Full Movie Online Free Ar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Action, Thriller, Science Fiction, Thriller, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://megacinema21.com/movie/577922/tenet.html</td>\n",
       "      <td>[{'ratingvalue': '4.7', 'worstrating': '1', 'r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'Sammy'}, {'name': 'Archibald'}, {'n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>https://image.tmdb.org/t/p/original/3GwYDxFCzP...</td>\n",
       "      <td>[sea, norway, work, language, espionage, crime...</td>\n",
       "      <td>[{'name': 'Estonia, United Kingdom, United Sta...</td>\n",
       "      <td>Tenet  2020  Full Movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1203 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id                                         name  \\\n",
       "0          0                         Beast No More (2019)   \n",
       "1          1             Superman: Man of Tomorrow (2020)   \n",
       "2          2                         The Discarded (2020)   \n",
       "3          3                             Souvenirs (2020)   \n",
       "4          4                            Robot Riot (2020)   \n",
       "...      ...                                          ...   \n",
       "1198      40  Bill & Ted Face the Music (2020) Full Movie   \n",
       "1199      41                      Mulan (2020) Full Movie   \n",
       "1200      42          Rambo: Last Blood (2019) Full Movie   \n",
       "1201      43              The Good Liar (2019) Full Movie   \n",
       "1202      44                      Tenet (2020) Full Movie   \n",
       "\n",
       "                                            description            director  \\\n",
       "0     Beast No More 123movies Watch Online Streaming...       Aaron Warwick   \n",
       "1     Superman: Man of Tomorrow 123movies Watch Onli...        Chris Palmer   \n",
       "2     The Discarded 123movies Watch Online Streaming...    Piotr Skowronski   \n",
       "3     Souvenirs 123movies Watch Online Streaming Fre...         Anna Mikami   \n",
       "4     Robot Riot 123movies Watch Online Streaming Fr...  Ryan Staples Scott   \n",
       "...                                                 ...                 ...   \n",
       "1198  Watch Bill & Ted Face the Music (2020) : Full ...                 NaN   \n",
       "1199  Watch Mulan (2020) : Full Movie Online Free Wh...                 NaN   \n",
       "1200  Watch Rambo: Last Blood (2019) : Full Movie On...                 NaN   \n",
       "1201  Watch The Good Liar (2019) : Full Movie Online...                 NaN   \n",
       "1202  Watch Tenet (2020) : Full Movie Online Free Ar...                 NaN   \n",
       "\n",
       "     duration                                              genre  \\\n",
       "0         N/A                                 [Horror, Thriller]   \n",
       "1      86 min               [Science Fiction, Animation, Action]   \n",
       "2      86 min                                           Thriller   \n",
       "3      84 min                                           Thriller   \n",
       "4      88 min                          [Science Fiction, Action]   \n",
       "...       ...                                                ...   \n",
       "1198      NaN  [Comedy, Comedy, Science Fiction, Adventure, S...   \n",
       "1199      NaN  [War, Drama, Adventure, Drama, Action, War, Fa...   \n",
       "1200      NaN  [Thriller, Drama, Action, Thriller, Drama, Act...   \n",
       "1201      NaN     [Mystery, Drama, Crime, Drama, Mystery, Crime]   \n",
       "1202      NaN  [Action, Thriller, Science Fiction, Thriller, ...   \n",
       "\n",
       "                                                    url  \\\n",
       "0                https://123moviesfx.com/beast-no-more/   \n",
       "1     https://123moviesfx.com/superman-man-of-tomorrow/   \n",
       "2                https://123moviesfx.com/the-discarded/   \n",
       "3                    https://123moviesfx.com/souvenirs/   \n",
       "4                   https://123moviesfx.com/robot-riot/   \n",
       "...                                                 ...   \n",
       "1198                                                NaN   \n",
       "1199                                                NaN   \n",
       "1200                                                NaN   \n",
       "1201                                                NaN   \n",
       "1202                                                NaN   \n",
       "\n",
       "                                               headline  \\\n",
       "0        Hello, Little Lamb. Mary Jane's Got a New Son.   \n",
       "1     Before he was the Man of Steel, he was the Man...   \n",
       "2                                                  None   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "1198                                                NaN   \n",
       "1199                                                NaN   \n",
       "1200                                                NaN   \n",
       "1201                                                NaN   \n",
       "1202                                                NaN   \n",
       "\n",
       "                                               page_url  \\\n",
       "0                https://123moviesfx.com/beast-no-more/   \n",
       "1     https://123moviesfx.com/superman-man-of-tomorrow/   \n",
       "2                https://123moviesfx.com/the-discarded/   \n",
       "3                    https://123moviesfx.com/souvenirs/   \n",
       "4                   https://123moviesfx.com/robot-riot/   \n",
       "...                                                 ...   \n",
       "1198  http://megacinema21.com/movie/501979/bill-ted-...   \n",
       "1199    http://megacinema21.com/movie/337401/mulan.html   \n",
       "1200  http://megacinema21.com/movie/522938/rambo-las...   \n",
       "1201  http://megacinema21.com/movie/511322/the-good-...   \n",
       "1202    http://megacinema21.com/movie/577922/tenet.html   \n",
       "\n",
       "                                        aggregaterating ratingvalue  \\\n",
       "0                                                   NaN         NaN   \n",
       "1                                                   NaN         NaN   \n",
       "2                                                   NaN         NaN   \n",
       "3                                                   NaN         NaN   \n",
       "4                                                   NaN         NaN   \n",
       "...                                                 ...         ...   \n",
       "1198  [{'ratingvalue': '4.7', 'worstrating': '1', 'r...         NaN   \n",
       "1199  [{'ratingvalue': '4.7', 'worstrating': '1', 'r...         NaN   \n",
       "1200  [{'ratingvalue': '4.7', 'worstrating': '1', 'r...         NaN   \n",
       "1201  [{'ratingvalue': '4.7', 'worstrating': '1', 'r...         NaN   \n",
       "1202  [{'ratingvalue': '4.7', 'worstrating': '1', 'r...         NaN   \n",
       "\n",
       "     datecreated                                             actors author  \\\n",
       "0            NaN                                                NaN    NaN   \n",
       "1            NaN                                                NaN    NaN   \n",
       "2            NaN                                                NaN    NaN   \n",
       "3            NaN                                                NaN    NaN   \n",
       "4            NaN                                                NaN    NaN   \n",
       "...          ...                                                ...    ...   \n",
       "1198         NaN  [{'name': 'Gypsy'}, {'name': 'Ling Lun'}, {'na...    NaN   \n",
       "1199         NaN  [{'name': 'The Chancellor'}, {'name': 'Bati Te...    NaN   \n",
       "1200         NaN  [{'name': 'Doctor Sergio'}, {'name': 'Bouncer'...    NaN   \n",
       "1201         NaN  [{'name': 'Steven'}, {'name': 'Vincent'}, {'na...    NaN   \n",
       "1202         NaN  [{'name': 'Sammy'}, {'name': 'Archibald'}, {'n...    NaN   \n",
       "\n",
       "     datemodified datepublished  \\\n",
       "0             NaN           NaN   \n",
       "1             NaN           NaN   \n",
       "2             NaN           NaN   \n",
       "3             NaN           NaN   \n",
       "4             NaN           NaN   \n",
       "...           ...           ...   \n",
       "1198          NaN    2020-08-27   \n",
       "1199          NaN    2020-09-10   \n",
       "1200          NaN    2019-09-19   \n",
       "1201          NaN    2019-11-08   \n",
       "1202          NaN    2020-08-22   \n",
       "\n",
       "                                                  image  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1198  https://image.tmdb.org/t/p/original/oazPqs1z78...   \n",
       "1199  https://image.tmdb.org/t/p/original/pbAszLhGyW...   \n",
       "1200  https://image.tmdb.org/t/p/original/iJtcxqrWDf...   \n",
       "1201  https://image.tmdb.org/t/p/original/du6TQLtjXH...   \n",
       "1202  https://image.tmdb.org/t/p/original/3GwYDxFCzP...   \n",
       "\n",
       "                                               keywords  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1198  [music, guitar, time travel, music, sequel, fa...   \n",
       "1199  [costumes, courage, honor, martial arts, heroi...   \n",
       "1200  [mexican american border, human trafficking, s...   \n",
       "1201  [based on novel or book, based on novel or boo...   \n",
       "1202  [sea, norway, work, language, espionage, crime...   \n",
       "\n",
       "                                                creator  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1198  [{'name': 'United States of America'}, {'name'...   \n",
       "1199  [{'name': 'Walt Disney Pictures, China Film Gr...   \n",
       "1200  [{'name': 'Millennium Films, Balboa Production...   \n",
       "1201  [{'name': 'Germany, United Kingdom, United Sta...   \n",
       "1202  [{'name': 'Estonia, United Kingdom, United Sta...   \n",
       "\n",
       "                                       new_column  \n",
       "0                            Beast No More  2019   \n",
       "1                Superman  Man of Tomorrow  2020   \n",
       "2                            The Discarded  2020   \n",
       "3                                Souvenirs  2020   \n",
       "4                               Robot Riot  2020   \n",
       "...                                           ...  \n",
       "1198  Bill   Ted Face the Music  2020  Full Movie  \n",
       "1199                      Mulan  2020  Full Movie  \n",
       "1200          Rambo  Last Blood  2019  Full Movie  \n",
       "1201              The Good Liar  2019  Full Movie  \n",
       "1202                      Tenet  2020  Full Movie  \n",
       "\n",
       "[1203 rows x 20 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punctuations(movie_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "86d6faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_empty_rows(df):\n",
    "    rows = []\n",
    "    for i, row in enumerate(df['director']):\n",
    "        if type(row) != str:\n",
    "            rows.append(i)\n",
    "    df_clean = df.drop(index=rows)\n",
    "    df_clean = df_clean.reset_index(drop=True)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f866cac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>director</th>\n",
       "      <th>duration</th>\n",
       "      <th>genre</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "      <th>page_url</th>\n",
       "      <th>aggregaterating</th>\n",
       "      <th>ratingvalue</th>\n",
       "      <th>datecreated</th>\n",
       "      <th>actors</th>\n",
       "      <th>author</th>\n",
       "      <th>datemodified</th>\n",
       "      <th>datepublished</th>\n",
       "      <th>image</th>\n",
       "      <th>keywords</th>\n",
       "      <th>creator</th>\n",
       "      <th>new_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Beast No More (2019)</td>\n",
       "      <td>Beast No More 123movies Watch Online Streaming...</td>\n",
       "      <td>Aaron Warwick</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[Horror, Thriller]</td>\n",
       "      <td>https://123moviesfx.com/beast-no-more/</td>\n",
       "      <td>Hello, Little Lamb. Mary Jane's Got a New Son.</td>\n",
       "      <td>https://123moviesfx.com/beast-no-more/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beast No More  2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Superman: Man of Tomorrow (2020)</td>\n",
       "      <td>Superman: Man of Tomorrow 123movies Watch Onli...</td>\n",
       "      <td>Chris Palmer</td>\n",
       "      <td>86 min</td>\n",
       "      <td>[Science Fiction, Animation, Action]</td>\n",
       "      <td>https://123moviesfx.com/superman-man-of-tomorrow/</td>\n",
       "      <td>Before he was the Man of Steel, he was the Man...</td>\n",
       "      <td>https://123moviesfx.com/superman-man-of-tomorrow/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Superman  Man of Tomorrow  2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Discarded (2020)</td>\n",
       "      <td>The Discarded 123movies Watch Online Streaming...</td>\n",
       "      <td>Piotr Skowronski</td>\n",
       "      <td>86 min</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>https://123moviesfx.com/the-discarded/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://123moviesfx.com/the-discarded/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Discarded  2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Souvenirs (2020)</td>\n",
       "      <td>Souvenirs 123movies Watch Online Streaming Fre...</td>\n",
       "      <td>Anna Mikami</td>\n",
       "      <td>84 min</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>https://123moviesfx.com/souvenirs/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://123moviesfx.com/souvenirs/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Souvenirs  2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Robot Riot (2020)</td>\n",
       "      <td>Robot Riot 123movies Watch Online Streaming Fr...</td>\n",
       "      <td>Ryan Staples Scott</td>\n",
       "      <td>88 min</td>\n",
       "      <td>[Science Fiction, Action]</td>\n",
       "      <td>https://123moviesfx.com/robot-riot/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://123moviesfx.com/robot-riot/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robot Riot  2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>78</td>\n",
       "      <td>Tribal Get Out Alive (2020)</td>\n",
       "      <td>Tribal Get Out Alive 123movies Watch Online St...</td>\n",
       "      <td>Matt Routledge</td>\n",
       "      <td>86 min</td>\n",
       "      <td>[Horror, Action, Thriller]</td>\n",
       "      <td>https://123moviesfx.com/tribal-get-out-alive/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://123moviesfx.com/tribal-get-out-alive/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tribal Get Out Alive  2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>79</td>\n",
       "      <td>Deathstroke: Knights &amp; Dragons</td>\n",
       "      <td>Deathstroke: Knights &amp; Dragons 123movies Watch...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[Comedy, Animation, Mystery, Adventure, Action...</td>\n",
       "      <td>https://123moviesfx.com/deathstroke-knights-dr...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://123moviesfx.com/deathstroke-knights-dr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deathstroke  Knights   Dragons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>80</td>\n",
       "      <td>Only the Animals (2019)</td>\n",
       "      <td>Only the Animals 123movies Watch Online Stream...</td>\n",
       "      <td>Dominik Moll</td>\n",
       "      <td>117 min</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>https://123moviesfx.com/only-the-animals/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://123moviesfx.com/only-the-animals/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Only the Animals  2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>81</td>\n",
       "      <td>La Llorona (2020)</td>\n",
       "      <td>La Llorona 123movies Watch Online Streaming Fr...</td>\n",
       "      <td>Jayro Bustamante</td>\n",
       "      <td>97 min</td>\n",
       "      <td>[Horror, Thriller]</td>\n",
       "      <td>https://123moviesfx.com/la-llorona/</td>\n",
       "      <td>The past will haunt you.</td>\n",
       "      <td>https://123moviesfx.com/la-llorona/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La Llorona  2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>82</td>\n",
       "      <td>The Tax Collector (2020)</td>\n",
       "      <td>The Tax Collector 123movies Watch Online Strea...</td>\n",
       "      <td>David Ayer</td>\n",
       "      <td>95 min</td>\n",
       "      <td>[Crime, Thriller, Action]</td>\n",
       "      <td>https://123moviesfx.com/the-tax-collector/</td>\n",
       "      <td>Payback comes with interest.</td>\n",
       "      <td>https://123moviesfx.com/the-tax-collector/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Tax Collector  2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id                              name  \\\n",
       "0        0              Beast No More (2019)   \n",
       "1        1  Superman: Man of Tomorrow (2020)   \n",
       "2        2              The Discarded (2020)   \n",
       "3        3                  Souvenirs (2020)   \n",
       "4        4                 Robot Riot (2020)   \n",
       "..     ...                               ...   \n",
       "76      78       Tribal Get Out Alive (2020)   \n",
       "77      79    Deathstroke: Knights & Dragons   \n",
       "78      80           Only the Animals (2019)   \n",
       "79      81                 La Llorona (2020)   \n",
       "80      82          The Tax Collector (2020)   \n",
       "\n",
       "                                          description            director  \\\n",
       "0   Beast No More 123movies Watch Online Streaming...       Aaron Warwick   \n",
       "1   Superman: Man of Tomorrow 123movies Watch Onli...        Chris Palmer   \n",
       "2   The Discarded 123movies Watch Online Streaming...    Piotr Skowronski   \n",
       "3   Souvenirs 123movies Watch Online Streaming Fre...         Anna Mikami   \n",
       "4   Robot Riot 123movies Watch Online Streaming Fr...  Ryan Staples Scott   \n",
       "..                                                ...                 ...   \n",
       "76  Tribal Get Out Alive 123movies Watch Online St...      Matt Routledge   \n",
       "77  Deathstroke: Knights & Dragons 123movies Watch...                 N/A   \n",
       "78  Only the Animals 123movies Watch Online Stream...        Dominik Moll   \n",
       "79  La Llorona 123movies Watch Online Streaming Fr...    Jayro Bustamante   \n",
       "80  The Tax Collector 123movies Watch Online Strea...          David Ayer   \n",
       "\n",
       "   duration                                              genre  \\\n",
       "0       N/A                                 [Horror, Thriller]   \n",
       "1    86 min               [Science Fiction, Animation, Action]   \n",
       "2    86 min                                           Thriller   \n",
       "3    84 min                                           Thriller   \n",
       "4    88 min                          [Science Fiction, Action]   \n",
       "..      ...                                                ...   \n",
       "76   86 min                         [Horror, Action, Thriller]   \n",
       "77      N/A  [Comedy, Animation, Mystery, Adventure, Action...   \n",
       "78  117 min                                           Thriller   \n",
       "79   97 min                                 [Horror, Thriller]   \n",
       "80   95 min                          [Crime, Thriller, Action]   \n",
       "\n",
       "                                                  url  \\\n",
       "0              https://123moviesfx.com/beast-no-more/   \n",
       "1   https://123moviesfx.com/superman-man-of-tomorrow/   \n",
       "2              https://123moviesfx.com/the-discarded/   \n",
       "3                  https://123moviesfx.com/souvenirs/   \n",
       "4                 https://123moviesfx.com/robot-riot/   \n",
       "..                                                ...   \n",
       "76      https://123moviesfx.com/tribal-get-out-alive/   \n",
       "77  https://123moviesfx.com/deathstroke-knights-dr...   \n",
       "78          https://123moviesfx.com/only-the-animals/   \n",
       "79                https://123moviesfx.com/la-llorona/   \n",
       "80         https://123moviesfx.com/the-tax-collector/   \n",
       "\n",
       "                                             headline  \\\n",
       "0      Hello, Little Lamb. Mary Jane's Got a New Son.   \n",
       "1   Before he was the Man of Steel, he was the Man...   \n",
       "2                                                None   \n",
       "3                                                None   \n",
       "4                                                None   \n",
       "..                                                ...   \n",
       "76                                               None   \n",
       "77                                               None   \n",
       "78                                               None   \n",
       "79                           The past will haunt you.   \n",
       "80                       Payback comes with interest.   \n",
       "\n",
       "                                             page_url aggregaterating  \\\n",
       "0              https://123moviesfx.com/beast-no-more/             NaN   \n",
       "1   https://123moviesfx.com/superman-man-of-tomorrow/             NaN   \n",
       "2              https://123moviesfx.com/the-discarded/             NaN   \n",
       "3                  https://123moviesfx.com/souvenirs/             NaN   \n",
       "4                 https://123moviesfx.com/robot-riot/             NaN   \n",
       "..                                                ...             ...   \n",
       "76      https://123moviesfx.com/tribal-get-out-alive/             NaN   \n",
       "77  https://123moviesfx.com/deathstroke-knights-dr...             NaN   \n",
       "78          https://123moviesfx.com/only-the-animals/             NaN   \n",
       "79                https://123moviesfx.com/la-llorona/             NaN   \n",
       "80         https://123moviesfx.com/the-tax-collector/             NaN   \n",
       "\n",
       "   ratingvalue datecreated actors author datemodified datepublished image  \\\n",
       "0          NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "1          NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "2          NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "3          NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "4          NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "..         ...         ...    ...    ...          ...           ...   ...   \n",
       "76         NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "77         NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "78         NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "79         NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "80         NaN         NaN    NaN    NaN          NaN           NaN   NaN   \n",
       "\n",
       "   keywords creator                        new_column  \n",
       "0       NaN     NaN              Beast No More  2019   \n",
       "1       NaN     NaN  Superman  Man of Tomorrow  2020   \n",
       "2       NaN     NaN              The Discarded  2020   \n",
       "3       NaN     NaN                  Souvenirs  2020   \n",
       "4       NaN     NaN                 Robot Riot  2020   \n",
       "..      ...     ...                               ...  \n",
       "76      NaN     NaN       Tribal Get Out Alive  2020   \n",
       "77      NaN     NaN    Deathstroke  Knights   Dragons  \n",
       "78      NaN     NaN           Only the Animals  2019   \n",
       "79      NaN     NaN                 La Llorona  2020   \n",
       "80      NaN     NaN          The Tax Collector  2020   \n",
       "\n",
       "[81 rows x 20 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_empty_rows(movie_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a35cdbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_final = movie_clean['new_column'].values\n",
    "movie_final[80000:80200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6712be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(movie_final)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b636d665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:12:26: Doc2Vec lifecycle event {'params': 'Doc2Vec(dbow,d50,n5,mc5,s0.001,t3)', 'datetime': '2021-11-05T17:12:26.145527', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-5.10.0-8-amd64-x86_64-with-glibc2.10', 'event': 'created'}\n",
      "INFO - 17:12:26: collecting all words and their counts\n",
      "INFO - 17:12:26: PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "INFO - 17:12:26: collected 1774 word types and 1203 unique tags from a corpus of 1203 examples and 3888 words\n",
      "INFO - 17:12:26: Creating a fresh vocabulary\n",
      "INFO - 17:12:26: Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 49 unique words (2.762119503945885%% of original 1774, drops 1725)', 'datetime': '2021-11-05T17:12:26.173807', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-5.10.0-8-amd64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 17:12:26: Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1690 word corpus (43.46707818930041%% of original 3888, drops 2198)', 'datetime': '2021-11-05T17:12:26.175530', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-5.10.0-8-amd64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 17:12:26: deleting the raw counts dictionary of 1774 items\n",
      "INFO - 17:12:26: sample=0.001 downsamples 49 most-common words\n",
      "INFO - 17:12:26: Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 356.74839986570674 word corpus (21.1%% of prior 1690)', 'datetime': '2021-11-05T17:12:26.178413', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-5.10.0-8-amd64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 17:12:26: estimated required memory for 49 words and 50 dimensions: 525300 bytes\n",
      "INFO - 17:12:26: resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(vector_size=50, min_count = 5, epochs = 25, dm = 0)\n",
    "model.build_vocab(movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bfa4c485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:12:42: Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 49 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5', 'datetime': '2021-11-05T17:12:42.612402', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-5.10.0-8-amd64-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:42: EPOCH - 1 : training on 3888 raw words (1568 effective words) took 0.0s, 40708 effective words/s\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:42: EPOCH - 2 : training on 3888 raw words (1561 effective words) took 0.0s, 41796 effective words/s\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:42: EPOCH - 3 : training on 3888 raw words (1550 effective words) took 0.0s, 39842 effective words/s\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:42: EPOCH - 4 : training on 3888 raw words (1561 effective words) took 0.0s, 40661 effective words/s\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:42: EPOCH - 5 : training on 3888 raw words (1556 effective words) took 0.0s, 38443 effective words/s\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:42: EPOCH - 6 : training on 3888 raw words (1536 effective words) took 0.0s, 39555 effective words/s\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:42: EPOCH - 7 : training on 3888 raw words (1571 effective words) took 0.0s, 43183 effective words/s\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:42: EPOCH - 8 : training on 3888 raw words (1566 effective words) took 0.0s, 41603 effective words/s\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:42: EPOCH - 9 : training on 3888 raw words (1569 effective words) took 0.0s, 41952 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 10 : training on 3888 raw words (1562 effective words) took 0.0s, 33046 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 11 : training on 3888 raw words (1549 effective words) took 0.0s, 41110 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 12 : training on 3888 raw words (1567 effective words) took 0.0s, 52364 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 13 : training on 3888 raw words (1553 effective words) took 0.0s, 71384 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 14 : training on 3888 raw words (1538 effective words) took 0.0s, 33645 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 15 : training on 3888 raw words (1560 effective words) took 0.0s, 33582 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 16 : training on 3888 raw words (1554 effective words) took 0.0s, 44647 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 17 : training on 3888 raw words (1555 effective words) took 0.0s, 38662 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 18 : training on 3888 raw words (1558 effective words) took 0.0s, 48846 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 19 : training on 3888 raw words (1553 effective words) took 0.0s, 43180 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 20 : training on 3888 raw words (1545 effective words) took 0.0s, 44421 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 21 : training on 3888 raw words (1570 effective words) took 0.0s, 41690 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 22 : training on 3888 raw words (1557 effective words) took 0.0s, 44127 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 23 : training on 3888 raw words (1541 effective words) took 0.0s, 32715 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 24 : training on 3888 raw words (1539 effective words) took 0.0s, 41458 effective words/s\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:12:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:12:43: EPOCH - 25 : training on 3888 raw words (1566 effective words) took 0.0s, 33698 effective words/s\n",
      "INFO - 17:12:43: Doc2Vec lifecycle event {'msg': 'training on 97200 raw words (38905 effective words) took 1.1s, 36648 effective words/s', 'datetime': '2021-11-05T17:12:43.675291', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-5.10.0-8-amd64-x86_64-with-glibc2.10', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model.train(movie_data, total_examples=model.corpus_count, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2887f129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00781531  0.0037352   0.00798409  0.005862    0.00971727  0.00235976\n",
      "  0.00959233 -0.00481351  0.00117226 -0.00547802  0.00575311 -0.00959109\n",
      " -0.00011034 -0.0078412  -0.00415582 -0.00927934 -0.00263722 -0.00412717\n",
      "  0.00179887 -0.00370974  0.00958668 -0.00385113 -0.00998031  0.00503157\n",
      " -0.00359955  0.00526854  0.00354367 -0.00415286 -0.00968215  0.00817921\n",
      " -0.00954979  0.00642419  0.00573475 -0.0036512   0.00253601  0.0093827\n",
      " -0.00587097 -0.00598555 -0.00129008 -0.00944406 -0.00804561  0.0012107\n",
      "  0.00611531  0.00109837 -0.00240615 -0.0070088   0.00635914  0.00805409\n",
      " -0.00727993 -0.00395816]\n"
     ]
    }
   ],
   "source": [
    "movie_vector = model.infer_vector(movie_clean['name'])\n",
    "print(movie_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c22b2a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.5230412e-03],\n",
       "       [ 3.4986853e-04],\n",
       "       [ 6.6339254e-04],\n",
       "       [-6.2449425e-03],\n",
       "       [ 1.3779759e-03],\n",
       "       [-9.4274487e-03],\n",
       "       [-9.5011564e-03],\n",
       "       [ 4.5402693e-03],\n",
       "       [ 2.1843684e-03],\n",
       "       [ 9.4820894e-03],\n",
       "       [ 8.9704348e-03],\n",
       "       [ 7.0758569e-03],\n",
       "       [-8.4697092e-03],\n",
       "       [ 1.7201054e-03],\n",
       "       [ 4.5998096e-03],\n",
       "       [ 4.9362779e-03],\n",
       "       [-4.4988929e-03],\n",
       "       [-4.5277732e-03],\n",
       "       [ 1.5663696e-03],\n",
       "       [-2.0434863e-03],\n",
       "       [ 1.3189912e-03],\n",
       "       [-3.4254438e-03],\n",
       "       [ 7.4231671e-03],\n",
       "       [ 4.6300887e-05],\n",
       "       [-7.6287319e-03],\n",
       "       [ 6.5903380e-03],\n",
       "       [-5.8929259e-03],\n",
       "       [ 8.4285606e-03],\n",
       "       [ 2.9216863e-03],\n",
       "       [ 9.7406302e-03],\n",
       "       [ 9.4274487e-03],\n",
       "       [-7.3194527e-03],\n",
       "       [-5.2250517e-03],\n",
       "       [ 9.4598054e-04],\n",
       "       [ 4.7107125e-03],\n",
       "       [-6.9367541e-03],\n",
       "       [ 4.8315167e-04],\n",
       "       [-1.9679822e-03],\n",
       "       [ 2.5304032e-03],\n",
       "       [ 3.8994825e-03],\n",
       "       [ 4.6591139e-03],\n",
       "       [-2.4499565e-03],\n",
       "       [-4.4073150e-03],\n",
       "       [ 7.7767670e-03],\n",
       "       [ 5.6682886e-03],\n",
       "       [-6.5937019e-03],\n",
       "       [-9.2968056e-03],\n",
       "       [-4.1475324e-03],\n",
       "       [ 4.1884435e-03],\n",
       "       [-6.0530538e-03]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "book_vector.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "933bb9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00781531],\n",
       "       [ 0.0037352 ],\n",
       "       [ 0.00798409],\n",
       "       [ 0.005862  ],\n",
       "       [ 0.00971727],\n",
       "       [ 0.00235976],\n",
       "       [ 0.00959233],\n",
       "       [-0.00481351],\n",
       "       [ 0.00117226],\n",
       "       [-0.00547802],\n",
       "       [ 0.00575311],\n",
       "       [-0.00959109],\n",
       "       [-0.00011034],\n",
       "       [-0.0078412 ],\n",
       "       [-0.00415582],\n",
       "       [-0.00927934],\n",
       "       [-0.00263722],\n",
       "       [-0.00412717],\n",
       "       [ 0.00179887],\n",
       "       [-0.00370974],\n",
       "       [ 0.00958668],\n",
       "       [-0.00385113],\n",
       "       [-0.00998031],\n",
       "       [ 0.00503157],\n",
       "       [-0.00359955],\n",
       "       [ 0.00526854],\n",
       "       [ 0.00354367],\n",
       "       [-0.00415286],\n",
       "       [-0.00968215],\n",
       "       [ 0.00817921],\n",
       "       [-0.00954979],\n",
       "       [ 0.00642419],\n",
       "       [ 0.00573475],\n",
       "       [-0.0036512 ],\n",
       "       [ 0.00253601],\n",
       "       [ 0.0093827 ],\n",
       "       [-0.00587097],\n",
       "       [-0.00598555],\n",
       "       [-0.00129008],\n",
       "       [-0.00944406],\n",
       "       [-0.00804561],\n",
       "       [ 0.0012107 ],\n",
       "       [ 0.00611531],\n",
       "       [ 0.00109837],\n",
       "       [-0.00240615],\n",
       "       [-0.0070088 ],\n",
       "       [ 0.00635914],\n",
       "       [ 0.00805409],\n",
       "       [-0.00727993],\n",
       "       [-0.00395816]], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_vector.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6b1b4225",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 4.5230412e-03  3.4986853e-04  6.6339254e-04 -6.2449425e-03\n  1.3779759e-03 -9.4274487e-03 -9.5011564e-03  4.5402693e-03\n  2.1843684e-03  9.4820894e-03  8.9704348e-03  7.0758569e-03\n -8.4697092e-03  1.7201054e-03  4.5998096e-03  4.9362779e-03\n -4.4988929e-03 -4.5277732e-03  1.5663696e-03 -2.0434863e-03\n  1.3189912e-03 -3.4254438e-03  7.4231671e-03  4.6300887e-05\n -7.6287319e-03  6.5903380e-03 -5.8929259e-03  8.4285606e-03\n  2.9216863e-03  9.7406302e-03  9.4274487e-03 -7.3194527e-03\n -5.2250517e-03  9.4598054e-04  4.7107125e-03 -6.9367541e-03\n  4.8315167e-04 -1.9679822e-03  2.5304032e-03  3.8994825e-03\n  4.6591139e-03 -2.4499565e-03 -4.4073150e-03  7.7767670e-03\n  5.6682886e-03 -6.5937019e-03 -9.2968056e-03 -4.1475324e-03\n  4.1884435e-03 -6.0530538e-03].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-8d0158db5069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    144\u001b[0m                             estimator=estimator)\n\u001b[1;32m    145\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         X = check_array(X, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[0m\u001b[1;32m    147\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                         estimator=estimator)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    638\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 4.5230412e-03  3.4986853e-04  6.6339254e-04 -6.2449425e-03\n  1.3779759e-03 -9.4274487e-03 -9.5011564e-03  4.5402693e-03\n  2.1843684e-03  9.4820894e-03  8.9704348e-03  7.0758569e-03\n -8.4697092e-03  1.7201054e-03  4.5998096e-03  4.9362779e-03\n -4.4988929e-03 -4.5277732e-03  1.5663696e-03 -2.0434863e-03\n  1.3189912e-03 -3.4254438e-03  7.4231671e-03  4.6300887e-05\n -7.6287319e-03  6.5903380e-03 -5.8929259e-03  8.4285606e-03\n  2.9216863e-03  9.7406302e-03  9.4274487e-03 -7.3194527e-03\n -5.2250517e-03  9.4598054e-04  4.7107125e-03 -6.9367541e-03\n  4.8315167e-04 -1.9679822e-03  2.5304032e-03  3.8994825e-03\n  4.6591139e-03 -2.4499565e-03 -4.4073150e-03  7.7767670e-03\n  5.6682886e-03 -6.5937019e-03 -9.2968056e-03 -4.1475324e-03\n  4.1884435e-03 -6.0530538e-03].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "cosine_similarity(book_vector, movie_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e37f266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
