{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.6972958505411"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "psutil.virtual_memory().available * 100 / psutil.virtual_memory().total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = r'../../../src/data/LocalBusiness/Splitting_ManualCheck/Train_Test/train tables' + '/'\n",
    "trainTables = os.listdir(trainPath)\n",
    "testPath = r'../../../src/data/LocalBusiness/Splitting_ManualCheck/Train_Test/test tables' + '/'\n",
    "testTables = os.listdir(testPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in trainTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(trainPath + table)\n",
    "        df = df.loc[df['cluster_id'] != -100]\n",
    "        if df.empty:\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.DataFrame(df[['name', 'cluster_id']])\n",
    "        except:\n",
    "            continue\n",
    "        df = df.transpose()\n",
    "        columns = df.columns\n",
    "        if len(columns) < 23:\n",
    "            i = 0\n",
    "            for value in columns:\n",
    "                clusterID = df.iloc[:,i]['cluster_id']\n",
    "                name = df.iloc[:,i]['name']\n",
    "                if pd.isna(name):\n",
    "                    df = df.drop(df.columns[i], axis = 1)\n",
    "                else:                \n",
    "                    df.columns.values[i] = clusterID\n",
    "                    i = i + 1\n",
    "            df = df.iloc[:1] \n",
    "            if df.empty:\n",
    "                continue       \n",
    "            df.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Test/train tables' + '/' + table[:-8] + '.csv', index=False)\n",
    "        else:\n",
    "            j = 0\n",
    "            while len(columns) >= 0:\n",
    "                dfNew = df.iloc[:,:22]\n",
    "                df = df.iloc[:,22:]\n",
    "\n",
    "                if len(dfNew.columns) == len(df.columns):\n",
    "                    break\n",
    "                newColumns = dfNew.columns\n",
    "                i = 0\n",
    "                for value in newColumns:\n",
    "                    clusterID = dfNew.iloc[:,i]['cluster_id']\n",
    "                    name = dfNew.iloc[:,i]['name']\n",
    "                    if pd.isna(name):\n",
    "                        dfNew = dfNew.drop(dfNew.columns[i], axis = 1)\n",
    "                    else:                \n",
    "                        dfNew.columns.values[i] = clusterID\n",
    "                        i = i + 1\n",
    "                dfNew = dfNew.iloc[:1]\n",
    "                if dfNew.empty:\n",
    "                    continue \n",
    "                dfNew.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Test/train tables' + '/' + table[:-8] + '_' + str(j) + '.csv', index=False)  \n",
    "                j = j + 1 \n",
    "                columns = df.columns\n",
    "        \n",
    "\n",
    "for table in testTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(testPath + table)\n",
    "        df = df.loc[df['cluster_id'] != -100]\n",
    "        if df.empty:\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.DataFrame(df[['name', 'cluster_id']])\n",
    "        except:\n",
    "            continue\n",
    "        df = df.transpose()\n",
    "        columns = df.columns\n",
    "        if len(columns) < 23:\n",
    "            i = 0\n",
    "            for value in columns:\n",
    "                clusterID = df.iloc[:,i]['cluster_id']\n",
    "                name = df.iloc[:,i]['name']\n",
    "                if pd.isna(name):\n",
    "                    df = df.drop(df.columns[i], axis = 1)\n",
    "                else:                \n",
    "                    df.columns.values[i] = clusterID\n",
    "                    i = i + 1\n",
    "            df = df.iloc[:1] \n",
    "            if df.empty:\n",
    "                continue       \n",
    "            df.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Test/test tables' + '/' + table[:-8] + '.csv', index=False)\n",
    "        else:\n",
    "            j = 0\n",
    "            while len(columns) >= 0:\n",
    "                dfNew = df.iloc[:,:22]\n",
    "                df = df.iloc[:,22:]\n",
    "\n",
    "                if len(dfNew.columns) == len(df.columns):\n",
    "                    break\n",
    "                newColumns = dfNew.columns\n",
    "                i = 0\n",
    "                for value in newColumns:\n",
    "                    clusterID = dfNew.iloc[:,i]['cluster_id']\n",
    "                    name = dfNew.iloc[:,i]['name']\n",
    "                    if pd.isna(name):\n",
    "                        dfNew = dfNew.drop(dfNew.columns[i], axis = 1)\n",
    "                    else:                \n",
    "                        dfNew.columns.values[i] = clusterID\n",
    "                        i = i + 1\n",
    "                dfNew = dfNew.iloc[:1]\n",
    "                if dfNew.empty:\n",
    "                    continue \n",
    "                dfNew.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Test/test tables' + '/' + table[:-8] + '_' + str(j) + '.csv', index=False)  \n",
    "                j = j + 1 \n",
    "                columns = df.columns\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = r'../../../src/data/LocalBusiness/Splitting_ManualCheck/Train_Validation_Test/train_tables_cleaned' + '/'\n",
    "trainTables = os.listdir(trainPath)\n",
    "testPath = r'../../../src/data/LocalBusiness/Splitting_ManualCheck/Train_Validation_Test/test_tables_cleaned' + '/'\n",
    "testTables = os.listdir(testPath)\n",
    "valPath = r'../../../src/data/LocalBusiness/Splitting_ManualCheck/Train_Validation_Test/validation_tables_cleaned' + '/'\n",
    "valTables = os.listdir(valPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in trainTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(trainPath + table)\n",
    "        df = df.loc[df['cluster_id'] != -100]\n",
    "        if df.empty:\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.DataFrame(df[['name', 'cluster_id']])\n",
    "        except:\n",
    "            continue\n",
    "        df = df.transpose()\n",
    "        columns = df.columns\n",
    "        if len(columns) < 23:\n",
    "            i = 0\n",
    "            for value in columns:\n",
    "                clusterID = df.iloc[:,i]['cluster_id']\n",
    "                name = df.iloc[:,i]['name']\n",
    "                if pd.isna(name):\n",
    "                    df = df.drop(df.columns[i], axis = 1)\n",
    "                else:                \n",
    "                    df.columns.values[i] = clusterID\n",
    "                    i = i + 1\n",
    "            df = df.iloc[:1] \n",
    "            if df.empty:\n",
    "                continue       \n",
    "            df.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/train_csv' + '/' + table[:-8] + '.csv', index=False)\n",
    "        else:\n",
    "            j = 0\n",
    "            while len(columns) >= 0:\n",
    "                dfNew = df.iloc[:,:22]\n",
    "                df = df.iloc[:,22:]\n",
    "\n",
    "                if len(dfNew.columns) == len(df.columns):\n",
    "                    break\n",
    "                newColumns = dfNew.columns\n",
    "                i = 0\n",
    "                for value in newColumns:\n",
    "                    clusterID = dfNew.iloc[:,i]['cluster_id']\n",
    "                    name = dfNew.iloc[:,i]['name']\n",
    "                    if pd.isna(name):\n",
    "                        dfNew = dfNew.drop(dfNew.columns[i], axis = 1)\n",
    "                    else:                \n",
    "                        dfNew.columns.values[i] = clusterID\n",
    "                        i = i + 1\n",
    "                dfNew = dfNew.iloc[:1]\n",
    "                if dfNew.empty:\n",
    "                    continue \n",
    "                dfNew.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/train_csv' + '/' + table[:-8] + '_' + str(j) + '.csv', index=False)  \n",
    "                j = j + 1 \n",
    "                columns = df.columns\n",
    "        \n",
    "\n",
    "\n",
    "for table in testTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(testPath + table)\n",
    "        df = df.loc[df['cluster_id'] != -100]\n",
    "        if df.empty:\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.DataFrame(df[['name', 'cluster_id']])\n",
    "        except:\n",
    "            continue\n",
    "        df = df.transpose()\n",
    "        columns = df.columns\n",
    "        if len(columns) < 23:\n",
    "            i = 0\n",
    "            for value in columns:\n",
    "                clusterID = df.iloc[:,i]['cluster_id']\n",
    "                name = df.iloc[:,i]['name']\n",
    "                if pd.isna(name):\n",
    "                    df = df.drop(df.columns[i], axis = 1)\n",
    "                else:                \n",
    "                    df.columns.values[i] = clusterID\n",
    "                    i = i + 1\n",
    "            df = df.iloc[:1] \n",
    "            if df.empty:\n",
    "                continue       \n",
    "            df.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/test_csv' + '/' + table[:-8] + '.csv', index=False)\n",
    "        else:\n",
    "            j = 0\n",
    "            while len(columns) >= 0:\n",
    "                dfNew = df.iloc[:,:22]\n",
    "                df = df.iloc[:,22:]\n",
    "\n",
    "                if len(dfNew.columns) == len(df.columns):\n",
    "                    break\n",
    "                newColumns = dfNew.columns\n",
    "                i = 0\n",
    "                for value in newColumns:\n",
    "                    clusterID = dfNew.iloc[:,i]['cluster_id']\n",
    "                    name = dfNew.iloc[:,i]['name']\n",
    "                    if pd.isna(name):\n",
    "                        dfNew = dfNew.drop(dfNew.columns[i], axis = 1)\n",
    "                    else:                \n",
    "                        dfNew.columns.values[i] = clusterID\n",
    "                        i = i + 1\n",
    "                dfNew = dfNew.iloc[:1]\n",
    "                if dfNew.empty:\n",
    "                    continue \n",
    "                dfNew.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/test_csv' + '/' + table[:-8] + '_' + str(j) + '.csv', index=False)  \n",
    "                j = j + 1 \n",
    "                columns = df.columns\n",
    "\n",
    "\n",
    "for table in valTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(valPath + table)\n",
    "        df = df.loc[df['cluster_id'] != -100]\n",
    "        if df.empty:\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.DataFrame(df[['name', 'cluster_id']])\n",
    "        except:\n",
    "            continue\n",
    "        df = df.transpose()\n",
    "        columns = df.columns\n",
    "        if len(columns) < 23:\n",
    "            i = 0\n",
    "            for value in columns:\n",
    "                clusterID = df.iloc[:,i]['cluster_id']\n",
    "                name = df.iloc[:,i]['name']\n",
    "                if pd.isna(name):\n",
    "                    df = df.drop(df.columns[i], axis = 1)\n",
    "                else:                \n",
    "                    df.columns.values[i] = clusterID\n",
    "                    i = i + 1\n",
    "            df = df.iloc[:1] \n",
    "            if df.empty:\n",
    "                continue       \n",
    "            df.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/valid_csv' + '/' + table[:-8] + '.csv', index=False)\n",
    "        else:\n",
    "            j = 0\n",
    "            while len(columns) >= 0:\n",
    "                dfNew = df.iloc[:,:22]\n",
    "                df = df.iloc[:,22:]\n",
    "\n",
    "                if len(dfNew.columns) == len(df.columns):\n",
    "                    break\n",
    "                newColumns = dfNew.columns\n",
    "                i = 0\n",
    "                for value in newColumns:\n",
    "                    clusterID = dfNew.iloc[:,i]['cluster_id']\n",
    "                    name = dfNew.iloc[:,i]['name']\n",
    "                    if pd.isna(name):\n",
    "                        dfNew = dfNew.drop(dfNew.columns[i], axis = 1)\n",
    "                    else:                \n",
    "                        dfNew.columns.values[i] = clusterID\n",
    "                        i = i + 1\n",
    "                dfNew = dfNew.iloc[:1]\n",
    "                if dfNew.empty:\n",
    "                    continue \n",
    "                dfNew.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/valid_csv' + '/' + table[:-8] + '_' + str(j) + '.csv', index=False)  \n",
    "                j = j + 1 \n",
    "                columns = df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Test/train tables' + '/'\n",
    "trainTables = os.listdir(trainPath)\n",
    "testPath = r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Test/test tables' + '/'\n",
    "testTables = os.listdir(testPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableList = []\n",
    "columnList = []\n",
    "\n",
    "for table in trainTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(trainPath + table)\n",
    "        i = 0\n",
    "        for value in df.columns:\n",
    "            tableList.append(table)\n",
    "            columnList.append(i)\n",
    "            i = i + 1\n",
    "df = pd.DataFrame(list(zip(tableList, columnList)), columns=['fname', 'col_id'])\n",
    "df.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Test/train_label.csv')\n",
    "\n",
    "\n",
    "tableList = []\n",
    "columnList = []\n",
    "\n",
    "for table in testTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(testPath + table)\n",
    "        i = 0\n",
    "        for value in df.columns:\n",
    "            tableList.append(table)\n",
    "            columnList.append(i)\n",
    "            i = i + 1\n",
    "df = pd.DataFrame(list(zip(tableList, columnList)), columns=['fname', 'col_id'])\n",
    "df.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Test/test_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/train_csv' + '/'\n",
    "trainTables = os.listdir(trainPath)\n",
    "testPath = r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/test_csv' + '/'\n",
    "testTables = os.listdir(testPath)\n",
    "valPath = r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/valid_csv' + '/'\n",
    "valTables = os.listdir(valPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in trainTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(trainPath + table)\n",
    "        row = df.iloc[:1]\n",
    "        try:\n",
    "            test = len(row.values[0][0])\n",
    "        except:\n",
    "            os.remove(trainPath + table)\n",
    "\n",
    "for table in testTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(testPath + table)\n",
    "        row = df.iloc[:1]\n",
    "        try:\n",
    "            test = len(row.values[0][0])\n",
    "        except:\n",
    "            os.remove(testPath + table)\n",
    "\n",
    "for table in valTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(valPath + table)\n",
    "        row = df.iloc[:1]\n",
    "        try:\n",
    "            test = len(row.values[0][0])\n",
    "        except:\n",
    "            os.remove(valPath + table)            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/train_csv' + '/'\n",
    "trainTables = os.listdir(trainPath)\n",
    "testPath = r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/test_csv' + '/'\n",
    "testTables = os.listdir(testPath)\n",
    "valPath = r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/valid_csv' + '/'\n",
    "valTables = os.listdir(valPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableList = []\n",
    "columnList = []\n",
    "\n",
    "for table in trainTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(trainPath + table)\n",
    "        i = 0\n",
    "        for value in df.columns:\n",
    "            tableList.append(table)\n",
    "            columnList.append(i)\n",
    "            i = i + 1\n",
    "df = pd.DataFrame(list(zip(tableList, columnList)), columns=['fname', 'col_id'])\n",
    "df.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/train_label.csv', index=False)\n",
    "\n",
    "\n",
    "tableList = []\n",
    "columnList = []\n",
    "\n",
    "for table in testTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(testPath + table)\n",
    "        i = 0\n",
    "        for value in df.columns:\n",
    "            tableList.append(table)\n",
    "            columnList.append(i)\n",
    "            i = i + 1\n",
    "df = pd.DataFrame(list(zip(tableList, columnList)), columns=['fname', 'col_id'])\n",
    "df.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/test_label.csv', index=False)\n",
    "\n",
    "tableList = []\n",
    "columnList = []\n",
    "\n",
    "for table in valTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(valPath + table)\n",
    "        i = 0\n",
    "        for value in df.columns:\n",
    "            tableList.append(table)\n",
    "            columnList.append(i)\n",
    "            i = i + 1\n",
    "df = pd.DataFrame(list(zip(tableList, columnList)), columns=['fname', 'col_id'])\n",
    "df.to_csv(r'../../../src/data/LocalBusiness/Splitting_TabbieData/Train_Validation_Test/valid_label.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e6c05dd04d5f1ab156515bda71d539c3517fd88dab50801005ef579a3eac424"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
