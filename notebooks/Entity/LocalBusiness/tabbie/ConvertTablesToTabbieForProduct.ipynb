{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/train_cleaned' + '/'\n",
    "trainTables = os.listdir(trainPath)\n",
    "testPath = r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/test_cleaned' + '/'\n",
    "testTables = os.listdir(testPath)\n",
    "valPath = r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/val_cleaned' + '/'\n",
    "valTables = os.listdir(valPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in trainTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        productData = []\n",
    "        with gzip.open(trainPath + table, 'r') as dataFile:\n",
    "            for line in dataFile:\n",
    "                lineData = json.loads(line.decode('utf-8'))\n",
    "                lineData['origin'] = table\n",
    "                productData.append(lineData)\n",
    "        df = pd.DataFrame(productData)\n",
    "        df = df.loc[df['cluster_id'] != -100]\n",
    "        if df.empty:\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.DataFrame(df[['name', 'description', 'cluster_id']])\n",
    "        except:\n",
    "            continue\n",
    "        df = df.transpose()\n",
    "        columns = df.columns\n",
    "        if len(columns) < 23:\n",
    "            i = 0\n",
    "            for value in columns:\n",
    "                clusterID = df.iloc[:,i]['cluster_id']\n",
    "                df.columns.values[i] = clusterID\n",
    "                i = i + 1\n",
    "            df = df.iloc[:2]\n",
    "            df.to_csv(r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/TabbieData/train tables' + '/' + table[:-8] + '.csv', index=False)\n",
    "        else:\n",
    "            j = 0\n",
    "            while len(columns) >= 0:\n",
    "                dfNew = df.iloc[:,:22]\n",
    "                df = df.iloc[:,22:]\n",
    "\n",
    "                if len(dfNew.columns) == len(df.columns):\n",
    "                    break\n",
    "                newColumns = dfNew.columns\n",
    "                i = 0\n",
    "                for value in newColumns:\n",
    "                    clusterID = dfNew.iloc[:,i]['cluster_id']\n",
    "                    dfNew.columns.values[i] = clusterID\n",
    "                    i = i + 1\n",
    "                dfNew = dfNew.iloc[:1]\n",
    "                dfNew.to_csv(r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/TabbieData/train tables' + '/' + table[:-8] + '_' + str(j) + '.csv', index=False)  \n",
    "                j = j + 1 \n",
    "                columns = df.columns\n",
    "\n",
    "for table in testTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        productData = []\n",
    "        with gzip.open(testPath + table, 'r') as dataFile:\n",
    "            for line in dataFile:\n",
    "                lineData = json.loads(line.decode('utf-8'))\n",
    "                lineData['origin'] = table\n",
    "                productData.append(lineData)\n",
    "        df = pd.DataFrame(productData)\n",
    "        df = df.loc[df['cluster_id'] != -100]\n",
    "        if df.empty:\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.DataFrame(df[['name', 'description', 'cluster_id']])\n",
    "        except:\n",
    "            continue\n",
    "        df = df.transpose()\n",
    "        columns = df.columns\n",
    "        if len(columns) < 23:\n",
    "            i = 0\n",
    "            for value in columns:\n",
    "                clusterID = df.iloc[:,i]['cluster_id']\n",
    "                df.columns.values[i] = clusterID\n",
    "                i = i + 1\n",
    "            df = df.iloc[:2]\n",
    "            df.to_csv(r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/TabbieData/test tables' + '/' + table[:-8] + '.csv', index=False)\n",
    "        else:\n",
    "            j = 0\n",
    "            while len(columns) >= 0:\n",
    "                dfNew = df.iloc[:,:22]\n",
    "                df = df.iloc[:,22:]\n",
    "\n",
    "                if len(dfNew.columns) == len(df.columns):\n",
    "                    break\n",
    "                newColumns = dfNew.columns\n",
    "                i = 0\n",
    "                for value in newColumns:\n",
    "                    clusterID = dfNew.iloc[:,i]['cluster_id']\n",
    "                    dfNew.columns.values[i] = clusterID\n",
    "                    i = i + 1\n",
    "                dfNew = dfNew.iloc[:1]\n",
    "                dfNew.to_csv(r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/TabbieData/test tables' + '/' + table[:-8] + '_' + str(j) + '.csv', index=False)  \n",
    "                j = j + 1 \n",
    "                columns = df.columns\n",
    "\n",
    "for table in valTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        productData = []\n",
    "        with gzip.open(valPath + table, 'r') as dataFile:\n",
    "            for line in dataFile:\n",
    "                lineData = json.loads(line.decode('utf-8'))\n",
    "                lineData['origin'] = table\n",
    "                productData.append(lineData)\n",
    "        df = pd.DataFrame(productData)\n",
    "        df = df.loc[df['cluster_id'] != -100]\n",
    "        if df.empty:\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.DataFrame(df[['name', 'description', 'cluster_id']])\n",
    "        except:\n",
    "            continue\n",
    "        df = df.transpose()\n",
    "        columns = df.columns\n",
    "        if len(columns) < 23:\n",
    "            i = 0\n",
    "            for value in columns:\n",
    "                clusterID = df.iloc[:,i]['cluster_id']\n",
    "                df.columns.values[i] = clusterID\n",
    "                i = i + 1\n",
    "            df = df.iloc[:2]\n",
    "            df.to_csv(r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/TabbieData/validation tables' + '/' + table[:-8] + '.csv', index=False)\n",
    "        else:\n",
    "            j = 0\n",
    "            while len(columns) >= 0:\n",
    "                dfNew = df.iloc[:,:22]\n",
    "                df = df.iloc[:,22:]\n",
    "\n",
    "                if len(dfNew.columns) == len(df.columns):\n",
    "                    break\n",
    "                newColumns = dfNew.columns\n",
    "                i = 0\n",
    "                for value in newColumns:\n",
    "                    clusterID = dfNew.iloc[:,i]['cluster_id']\n",
    "                    dfNew.columns.values[i] = clusterID\n",
    "                    i = i + 1\n",
    "                dfNew = dfNew.iloc[:1]\n",
    "                dfNew.to_csv(r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/TabbieData/validation tables' + '/' + table[:-8] + '_' + str(j) + '.csv', index=False)  \n",
    "                j = j + 1 \n",
    "                columns = df.columns                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/TabbieData/train tables' + '/'\n",
    "trainTables = os.listdir(trainPath)\n",
    "testPath = r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/TabbieData/test tables' + '/'\n",
    "testTables = os.listdir(testPath)\n",
    "valPath = r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/TabbieData/validation tables' + '/'\n",
    "valTables = os.listdir(valPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableList = []\n",
    "columnList = []\n",
    "\n",
    "for table in trainTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(trainPath + table)\n",
    "        i = 0\n",
    "        for value in df.columns:\n",
    "            tableList.append(table)\n",
    "            columnList.append(i)\n",
    "            i = i + 1\n",
    "df = pd.DataFrame(list(zip(tableList, columnList)), columns=['fname', 'col_id'])\n",
    "df.to_csv(r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/TabbieData/train_label.csv', index=False)\n",
    "\n",
    "\n",
    "tableList = []\n",
    "columnList = []\n",
    "\n",
    "for table in testTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(testPath + table)\n",
    "        i = 0\n",
    "        for value in df.columns:\n",
    "            tableList.append(table)\n",
    "            columnList.append(i)\n",
    "            i = i + 1\n",
    "df = pd.DataFrame(list(zip(tableList, columnList)), columns=['fname', 'col_id'])\n",
    "df.to_csv(r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/TabbieData/test_label.csv', index=False)\n",
    "\n",
    "tableList = []\n",
    "columnList = []\n",
    "\n",
    "for table in valTables:\n",
    "    if table != '.ipynb_checkpoints':\n",
    "        df = pd.read_csv(valPath + table)\n",
    "        i = 0\n",
    "        for value in df.columns:\n",
    "            tableList.append(table)\n",
    "            columnList.append(i)\n",
    "            i = i + 1\n",
    "df = pd.DataFrame(list(zip(tableList, columnList)), columns=['fname', 'col_id'])\n",
    "df.to_csv(r'../../../src/data/product/train_test_split/output_unfiltered_tables/large/after_manual_checking/TabbieData/valid_label.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e6c05dd04d5f1ab156515bda71d539c3517fd88dab50801005ef579a3eac424"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
