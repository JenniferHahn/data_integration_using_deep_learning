{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a2f79c8",
   "metadata": {},
   "source": [
    "<h3> General Mapping Idea: </h3>\n",
    "  \n",
    "**Combined Rule-based Matching Strategy:** two sources of information: telephone number,  geological information (address & geo) <br>\n",
    "1). parse geological information to retrive country, state, zip, etc., data of entities <br>\n",
    "2). normalize telephone numbers (and ideally decompose telephone numbers into country code, area code, and national number for better matching outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4f8cbb",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c65d219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import gzip\n",
    "import shutil \n",
    "\n",
    "# import geopy.distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b000b64",
   "metadata": {},
   "source": [
    " ### 2. Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3d7deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dataframes\n",
    "def concatenate_dataframe(source_path):\n",
    "    files = os.listdir(source_path)\n",
    "    # initialize a dataframe\n",
    "    df_final = pd.DataFrame()\n",
    "    for file in files:\n",
    "        df = pd.read_json(os.path.join(source_path, file), compression='gzip', lines=True)\n",
    "        df['table_id'] = file.strip('.json.gz')\n",
    "        df_final = pd.concat([df_final, df], ignore_index=True)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66206ebf",
   "metadata": {},
   "source": [
    "<b> Geological Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3a53d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "class EntityPreprocessor:\n",
    "    \"\"\"\n",
    "    iterator over cells in a column to flatten all dictionary-typed objects, \n",
    "    then extract values of all keys and save the values in the newly-added corresponding column\n",
    "    \n",
    "    Args:\n",
    "    df: dataframe to be preprocessed \n",
    "    cols: columns to be flattened\n",
    "    keys: a dictionary to store keys that have appeared in the columns\n",
    "    \n",
    "    Returns:\n",
    "    a new dataframe with appended columns\n",
    "    a dictionary store keys in user-specified columns\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, cols=[], keys={}):\n",
    "        self.df = df\n",
    "        self.cols = cols\n",
    "        self.keys = keys\n",
    "    \n",
    "    # collect keys \n",
    "    def collect_keys(self):\n",
    "        df = self.df\n",
    "        cols = self.cols\n",
    "        keys = self.keys\n",
    "        \n",
    "        for col in cols:\n",
    "            if not col in df.columns:\n",
    "                continue\n",
    "            # drop records without required data\n",
    "            tmp = df[~df[col].isna()][col]\n",
    "            # initialize a list to store keys appearing in the current column\n",
    "            result_list = []\n",
    "            for item in tmp:\n",
    "                try:\n",
    "                    for key in item.keys():\n",
    "                        if not key in result_list:\n",
    "                            result_list.append(key)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # append to the dictionary\n",
    "            keys[col] = result_list\n",
    "            \n",
    "        self.keys = keys\n",
    "        return keys\n",
    "\n",
    "    # flatten a dictionary\n",
    "    @staticmethod\n",
    "    def _extract_value(iterator, key):\n",
    "        if isinstance(iterator, dict): \n",
    "            return iterator.get(key, None)\n",
    "        else: \n",
    "            return None\n",
    "\n",
    "    # append new columns to store extracted infomation\n",
    "    def column_parser(self, inplace=False): \n",
    "        df = self.df\n",
    "        cols = self.cols\n",
    "        keys = self.keys\n",
    "        if keys == {}:\n",
    "            raise Error(\"self.keys is an empty list. Please collect keys first\")\n",
    "        \n",
    "        for col in cols:\n",
    "            if not col in df.columns:\n",
    "                continue\n",
    "            keys_list = keys[col]\n",
    "            for key in keys_list:\n",
    "                # column_parser.key = key\n",
    "                if key != 'telephone':\n",
    "                    df[key] = None\n",
    "                    df[key] = df[col].apply(EntityPreprocessor._extract_value, args=(key,))\n",
    "                else:\n",
    "                    df['telephone_'+ col] = df[col].apply(EntityPreprocessor._extract_value, args=(key,))\n",
    "        if inplace:\n",
    "            self.df = df\n",
    "        else: \n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d0a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo distance calculation\n",
    "def geo_distance(coords_1, coords_2):\n",
    "    return geopy.distance.vincenty(coords_1, coords_2).km"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd58a23",
   "metadata": {},
   "source": [
    "<b> Telephone Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8341b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# telephone preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44655203",
   "metadata": {},
   "source": [
    "<b> Entity Name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add1a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jaccard similarity calculation\n",
    "def jaccard_distance(s1, s2):\n",
    "    tokenized_s1 = set(s1.split(' '))\n",
    "    tokenized_s2 = set(s2.split(' '))\n",
    "    overlap = tokenized_s1.intersection(tokenized_s2) \n",
    "    union = tokenized_s1.union(tokenized_s2) \n",
    "    \n",
    "    return len(overlap)/len(union)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50992ac1",
   "metadata": {},
   "source": [
    "### 3. Exploratory Analysis using Top100 Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aed8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_parent = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(path_parent, 'src/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b444d8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work-ceph/bizer-tp2021/data_integration_using_deep_learning/src/data/Hotel\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de363bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work-ceph/bizer-tp2021/data_integration_using_deep_learning/src/data/Restaurant/Restaurant_top100\n"
     ]
    }
   ],
   "source": [
    "cd ../Restaurant_top100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "028af01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir geo_preprocessed_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b986c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "source_path = os.path.join(data_path, 'Restaurant/Restaurant_minimum3/final_iteration')\n",
    "target_path = os.path.join(data_path, 'Restaurant/Restaurant_minimum3/geo_preprocessed_v2')\n",
    "gzfiles = os.listdir(source_path) \n",
    "\n",
    "for file in gzfiles: \n",
    "    if not file.endswith('.json.gz'):\n",
    "        continue\n",
    "    df_in = pd.read_json(os.path.join(source_path, file), compression='gzip', lines=True)\n",
    "    local_business = EntityPreprocessor(df_in, cols=['address','geo'])\n",
    "    keys = local_business.collect_keys()\n",
    "    df_out = local_business.column_parser()\n",
    "    df_out.to_json(os.path.join(target_path, file), compression='gzip', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27d81ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "source_path = os.path.join(data_path, 'Restaurant/Restaurant_top100/final_iteration')\n",
    "target_path = os.path.join(data_path, 'Restaurant/Restaurant_top100/geo_preprocessed_v2')\n",
    "gzfiles = os.listdir(source_path) \n",
    "\n",
    "for file in gzfiles: \n",
    "    if not file.endswith('.json.gz'):\n",
    "        continue\n",
    "    df_in = pd.read_json(os.path.join(source_path, file), compression='gzip', lines=True)\n",
    "    local_business = EntityPreprocessor(df_in, cols=['address','geo'])\n",
    "    keys = local_business.collect_keys()\n",
    "    df_out = local_business.column_parser()\n",
    "    df_out.to_json(os.path.join(target_path, file), compression='gzip', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7130a02b",
   "metadata": {},
   "source": [
    "**Geo Info Preprocessing**  <br>\n",
    "**Results** <br>\n",
    "**1) Address Keys:**<br> \n",
    "'addressregion' (57.7%), 'postalcode'(42.8%), 'streetaddress'(52.7%),'addresslocality' (66.6%), 'addresscountry' (40.9%), 'postofficeboxnumber'(1.3%), 'citystatezip('1.3%'), 'telephone_address'(5.9%), 'faxnumber'(2.9%), 'sameas(3.1%)' \n",
    "\n",
    "It seems that *'addressregion', 'addresslocality', 'addresscountry', 'postalcode'* can be potentially used as identifiers. There is a python library called ***pgeocode*** that can extract more infomation from postal codes (conditional on country is known). (Ref: https://www.journaldev.com/49094/find-address-from-zip-code-in-python) <br> \n",
    "\n",
    "Besides, it is noticable that most records in 'addressregion' refer to states of different countries, which, however, might be named with synonyms. The normalized *'addressregion'* values can be used to select entties from a given country. Then the updated column *'addresscountry'* can be further be used during the parsing of telephone numbers and postal codes. \n",
    "\n",
    "**2) Geo Keys:** <br>\n",
    "'longitude'('25.1%'), 'latitude'(30.4%)\n",
    "\n",
    "The longitudes and latitudes of entities might refer to those of entity headquarters. Notice that *'address* often refers to a specific entity branch, a better decision is probably to replace the longitudes and latitudes from those extracted from postal codes using ***pgepcode***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a99554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
