{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1d66139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b8a390d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work-ceph/bizer-tp2021/data_integration_using_deep_learning\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c3acbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work-ceph/bizer-tp2021/data_integration_using_deep_learning'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_path = os.path.dirname(os.getcwd()) + '/data_integration_using_deep_learning'\n",
    "parent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f790044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_path = parent_path + \"/src/data/LocalBusiness\" \n",
    "cleaned_file = '20-12-21_ClusterFile_withCleaning'\n",
    "\n",
    "LB_top100_path =  parent_path + \"/src/data/LocalBusiness/LocalBusiness_top100/geo_preprocessed_v3\" \n",
    "LB_min3_path =  parent_path + \"/src/data/LocalBusiness/LocalBusiness_minimum3/geo_preprocessed_v3\" \n",
    "Hotel_top100_path =  parent_path + \"/src/data/Hotel/Hotel_top100/geo_preprocessed_v3\" \n",
    "Hotel_min3_path =  parent_path + \"/src/data/Hotel/Hotel_minimum3/geo_preprocessed_v3\" \n",
    "Restaurant_top100_path =  parent_path + \"/src/data/Restaurant/Restaurant_top100/geo_preprocessed_v3\" \n",
    "Restaurant_min3_path =  parent_path + \"/src/data/Restaurant/Restaurant_minimum3/geo_preprocessed_v3\" \n",
    "\n",
    "splitting3_path = parent_path + \"/src/data/LocalBusiness/Splitting_12.20/Train_Validation_Test\"\n",
    "splitting2_path = parent_path + \"/src/data/LocalBusiness/Splitting_12.20/Train_Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9577dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tables3 = pd.read_csv(os.path.join(splitting3_path, 'training tables.csv')).drop(columns='Unnamed: 0')['0'].tolist()\n",
    "val_tables3 = pd.read_csv(os.path.join(splitting3_path, 'validation tables.csv')).drop(columns='Unnamed: 0')['0'].tolist()\n",
    "test_tables3 = pd.read_csv(os.path.join(splitting3_path, 'testing tables.csv')).drop(columns='Unnamed: 0')['0'].tolist()\n",
    "\n",
    "train_tables2 = pd.read_csv(os.path.join(splitting2_path, 'training tables_v2.csv')).drop(columns='Unnamed: 0')['0'].tolist()\n",
    "test_tables2 = pd.read_csv(os.path.join(splitting2_path, 'testing tables_v2.csv')).drop(columns='Unnamed: 0')['0'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b271a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_json(os.path.join(cleaned_path, cleaned_file), compression='gzip', orient='records', lines=True)\n",
    "selected_tables = df_cleaned[df_cleaned['clusterNtables']>=8]['table_id'].unique()\n",
    "\n",
    "df_cleaned = df_cleaned[['cluster_id', 'table_id', 'row_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc65fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_paths = [LB_top100_path, LB_min3_path, Hotel_top100_path, Hotel_min3_path, Restaurant_top100_path, Restaurant_min3_path]\n",
    "target_paths = [splitting3_path, splitting2_path]\n",
    "\n",
    "for path in source_paths:\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        if not file in selected_tables:\n",
    "            continue\n",
    "        else:\n",
    "            df = pd.read_json(os.path.join(path,file), compression='gzip', orient='records', lines=True)\n",
    "            df['table_id'] = file\n",
    "            df_merge = df.merge(df_cleaned, how='left', on=['table_id', 'row_id'])\n",
    "            df_merge['cluster_id'].fillna(-100, inplace=True)\n",
    "            df_merge = df_merge.astype({'cluster_id': 'int32'})\n",
    "            \n",
    "            # export the files: train_val_test splitting\n",
    "            if file in train_tables3:\n",
    "                df_merge.to_json(os.path.join(splitting3_path + '/train tables', str(file)), \n",
    "                                 compression='gzip', orient='records', lines=True)\n",
    "            elif file in val_tables3:\n",
    "                df_merge.to_json(os.path.join(splitting3_path + '/validation tables', str(file)),\n",
    "                                 compression='gzip', orient='records', lines=True)\n",
    "            elif file in test_tables3:\n",
    "                df_merge.to_json(os.path.join(splitting3_path + '/test tables', str(file)),\n",
    "                                 compression='gzip', orient='records', lines=True)\n",
    "                \n",
    "            # export the files: train_test splitting\n",
    "            if file in train_tables2:\n",
    "                df_merge.to_json(os.path.join(splitting2_path + '/train tables', str(file)),\n",
    "                                 compression='gzip', orient='records', lines=True)\n",
    "            elif file in test_tables2:\n",
    "                df_merge.to_json(os.path.join(splitting2_path + '/test tables', str(file)),\n",
    "                                 compression='gzip', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "654f13bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(splitting2_path+'/test tables')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf8d385",
   "metadata": {},
   "source": [
    "<b>Full Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d2c2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(os.path.join(splitting2_path+'/test tables'))\n",
    "results = []\n",
    "for file in files:\n",
    "    df = pd.read_json(os.path.join(os.path.join(splitting2_path+'/test tables'),file), compression='gzip', orient='records', lines=True)\n",
    "    results.append(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0755d3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506.4668674698795\n",
      "29.0\n",
      "2\n",
      "42723\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results))\n",
    "print(np.median(results))\n",
    "print(np.min(results))\n",
    "print(np.max(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4851b233",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(os.path.join(splitting2_path+'/train tables'))\n",
    "results1 = []\n",
    "for file in files:\n",
    "    df = pd.read_json(os.path.join(os.path.join(splitting2_path+'/train tables'),file), compression='gzip', orient='records', lines=True)\n",
    "    results1.append(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3d46b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362.10599773670316\n",
      "27.0\n",
      "2\n",
      "29006\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results1))\n",
    "print(np.median(results1))\n",
    "print(np.min(results1))\n",
    "print(np.max(results1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b483b125",
   "metadata": {},
   "source": [
    "<b> Not -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2d4fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(os.path.join(splitting2_path+'/test tables'))\n",
    "results_S = []\n",
    "for file in files:\n",
    "    df = pd.read_json(os.path.join(os.path.join(splitting2_path+'/test tables'),file), compression='gzip', orient='records', lines=True)\n",
    "    df = df[df['cluster_id']!=-100]\n",
    "    results_S.append(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f1d6511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.916666666666668\n",
      "5.0\n",
      "1\n",
      "1587\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results_S))\n",
    "print(np.median(results_S))\n",
    "print(np.min(results_S))\n",
    "print(np.max(results_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12a30361",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(os.path.join(splitting2_path+'/train tables'))\n",
    "results1_S = []\n",
    "for file in files:\n",
    "    df = pd.read_json(os.path.join(os.path.join(splitting2_path+'/train tables'),file), compression='gzip', orient='records', lines=True)\n",
    "    df = df[df['cluster_id']!=-100]\n",
    "    results1_S.append(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9cea559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.504715201810637\n",
      "5.0\n",
      "1\n",
      "1319\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results1_S))\n",
    "print(np.median(results1_S))\n",
    "print(np.min(results1_S))\n",
    "print(np.max(results1_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc2d101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
